<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>81f4f57b38454692b1b792668eb7626c</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown"
data-vscode="{&quot;languageId&quot;:&quot;plaintext&quot;}">
<h1 id="i-introduction"><span class="math inline"><em>I</em></span>.
Introduction</h1>
<p>La prédiction du prix des maisons représente un défi majeur dans le
domaine de la data science et trouve de nombreuses applications
pratiques, notamment pour les <strong>agents immobiliers</strong>, les
<strong>acheteurs</strong>, les <strong>vendeurs</strong>, et les
<strong>investisseurs</strong>. Ce projet a pour ambition d’analyser et
de <strong>prédire la valeur marchande de biens immobiliers</strong> en
se basant sur une série de caractéristiques spécifiques. Le modèle de
prédiction des prix immobiliers peut être vu comme un modèle de
<strong>régression</strong> où la variable cible (le prix) dépend d’un
ensemble de <strong>variables explicatives</strong> qui décrivent les
caractéristiques des propriétés.</p>
<p>La particularité de cette problématique réside dans la nécessité de
bien comprendre l’influence de chaque <strong>caractéristique</strong>
(ou <em>feature</em>) sur la valeur d’un bien. En effet, des attributs
comme la <strong>superficie</strong>, le <strong>nombre de
chambres</strong>, la <strong>localisation</strong>, l’<strong>année de
construction</strong>, ou la <strong>qualité de la finition</strong>
peuvent avoir un impact direct ou indirect sur le prix final. En data
science, cette tâche consiste à trouver une <strong>fonction de
prédiction optimisée</strong> qui puisse capturer ces relations
complexes entre les variables et fournir une estimation aussi précise
que possible du prix.</p>
<h2 id="a-contexte-et-objectifs"><span
class="math inline"><em>a</em></span>. Contexte et Objectifs</h2>
<p>L’objectif principal de ce projet est de construire plusieurs
<strong>modèles de régression</strong> pour estimer les prix de maisons.
Cela comprend le développement de modèles simples, tels que des modèles
de base (<em>baseline</em>) pour une première estimation, ainsi que des
modèles plus sophistiqués capables de capturer des relations <strong>non
linéaires</strong> entre les variables. À travers cette étude, nous
explorerons des techniques de <strong>régression linéaire</strong> ainsi
que des <strong>modèles ensemblistes</strong> (par exemple, <em>Random
Forest</em> ou <em>Gradient Boosting</em>), reconnus pour leur capacité
à réduire le <strong>surapprentissage</strong> et à améliorer les
performances prédictives.</p>
<h2 id="b-étapes-du-projet"><span class="math inline"><em>b</em></span>.
Étapes du Projet</h2>
<p>Le projet est structuré en plusieurs étapes clés :</p>
<ol>
<li><strong>Exploration et Préparation des Données :</strong>
<ul>
<li>La première étape consiste à <strong>explorer et analyser le jeu de
données</strong> en profondeur, avec une analyse univariée et
multivariée des caractéristiques. Cela permet d’identifier les relations
existantes entre les variables explicatives et la variable cible (le
prix).</li>
<li>Ensuite, un <strong>nettoyage des données</strong> est effectué pour
traiter les valeurs manquantes, les erreurs de saisie, et les
incohérences. La préparation des données inclut également la
<strong>transformation et le typage des variables</strong> (par exemple,
transformation des variables catégorielles en variables numériques),
étape cruciale pour assurer la bonne performance des modèles de machine
learning.</li>
</ul></li>
<li><strong>Développement des Modèles de Régression :</strong>
<ul>
<li><p><strong>Modèle Baseline</strong> : En guise de référence, un
modèle de base est d’abord construit. Ce modèle simple se base sur des
moyennes ou des règles statistiques élémentaires pour fournir une
première estimation des prix. Bien qu’il soit rudimentaire, il sert de
point de comparaison pour évaluer l’amélioration obtenue avec les
modèles plus avancés.</p></li>
<li><p><strong>Régression Linéaire</strong> : La régression linéaire est
ensuite utilisée pour prédire les prix en fonction des variables
explicatives. Ce modèle est idéal pour comprendre les contributions
individuelles de chaque variable, car il attribue un coefficient
spécifique à chacune, permettant ainsi une interprétation directe de
leur influence sur le prix.</p></li>
<li><p><strong>Modèle Ensembliste</strong> (<em>Random Forest</em> ou
<em>Gradient Boosting</em>) : Enfin, nous mettons en œuvre un modèle
ensembliste, qui combine les prédictions de plusieurs sous-modèles pour
réduire l’erreur et améliorer la précision des prédictions. Ces modèles
sont particulièrement performants pour capturer des relations
<strong>non linéaires</strong> et <strong>complexes</strong> entre les
variables explicatives et le prix des maisons.</p></li>
</ul></li>
<li><strong>Évaluation et Analyse des Performances :</strong>
<ul>
<li><p>Pour évaluer la précision des prédictions, nous utiliserons des
métriques de performance comme l’<strong>erreur absolue moyenne</strong>
(<em>Mean Absolute Error - MAE</em>), le <strong>Root Mean Squared
Error</strong> (<em>RMSE</em>) et le <strong>coefficient de
détermination</strong> (<em><span
class="math inline"><em>R</em><sup>2</sup></span></em>). Ces indicateurs
permettent d’évaluer la qualité des prédictions et de comparer les
performances des différents modèles.</p></li>
<li><p>Une <strong>analyse des coefficients</strong> et des «
<em>feature importances</em> » (importance des caractéristiques) est
également effectuée pour comprendre quelles variables influencent le
plus la valeur d’un bien immobilier. Cette analyse permet d’identifier
les caractéristiques les plus significatives, ce qui est
particulièrement utile pour des applications pratiques de <strong>prise
de décision</strong> dans le secteur immobilier.</p></li>
</ul></li>
</ol>
<p>L’ensemble du projet sera réalisé dans un environnement
<strong>Python</strong>, en utilisant des bibliothèques comme
<code>NumPy</code>, <code>pandas</code>, <code>seaborn</code> et
<code>scikit-learn</code>.</p>
<h1 id="ii-importation-des-bibliothèques-et-du-jeu-de-données"><span
class="math inline"><em>I</em><em>I</em></span>. Importation des
bibliothèques et du jeu de données</h1>
</div>
<div class="cell code" data-execution_count="3">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importation des bibliothèques nécessaires</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   scipy <span class="im">import</span> stats</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   scipy.stats <span class="im">import</span> chi2_contingency, ttest_ind</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   sklearn.ensemble <span class="im">import</span> RandomForestRegressor, GradientBoostingRegressor</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   sklearn.metrics <span class="im">import</span> mean_absolute_error, r2_score, mean_squared_error</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span>   sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV, RandomizedSearchCV</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Chargement des données</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(filepath):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Charge le jeu de données et retourne un DataFrame.</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">        filepath (str): Le chemin vers le fichier CSV.</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: Le DataFrame contenant les données.</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pd.read_csv(filepath, sep<span class="op">=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyse des données</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> load_data(<span class="st">&quot;house_prices.csv&quot;</span>)  <span class="co"># Chargement du jeu de données</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>df.info()  <span class="co"># Affiche les informations sur les types de colonnes et les valeurs manquantes</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># print(df.head(10))</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Unexpected exception formatting exception. Falling back to standard exception
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Traceback (most recent call last):
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py&quot;, line 3508, in run_code
  File &quot;/var/folders/7n/_9qklb4s31s31j53dyk8hvf00000gn/T/ipykernel_75238/581928038.py&quot;, line 2, in &lt;module&gt;
    import numpy as np
ModuleNotFoundError: No module named &#39;numpy&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/pygments/styles/__init__.py&quot;, line 89, in get_style_by_name
ModuleNotFoundError: No module named &#39;pygments.styles.default&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py&quot;, line 2105, in showtraceback
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/ultratb.py&quot;, line 1428, in structured_traceback
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/ultratb.py&quot;, line 1319, in structured_traceback
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/ultratb.py&quot;, line 1172, in structured_traceback
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/ultratb.py&quot;, line 1062, in format_exception_as_a_whole
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/IPython/core/ultratb.py&quot;, line 1113, in get_records
  File &quot;/Users/del_son_as/Dropbox/Mac/Desktop/Predictions_Prix_Maison_Mathias_Kossivi/test/lib/python3.10/site-packages/pygments/styles/__init__.py&quot;, line 91, in get_style_by_name
pygments.util.ClassNotFound: Could not find style module &#39;default&#39;, though it should be builtin.
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2 id="a-description-de-la-base-de-données"><span
class="math inline"><em>a</em></span>. Description de la Base de
Données</h2>
<p>La base de données utilisée pour ce projet contient des informations
détaillées sur les caractéristiques des maisons et leur prix. Elle est
constituée de <strong><span class="math inline">14</span>
variables</strong>, dont une variable cible
(<strong><code>Price</code></strong>) et <span
class="math inline">13</span> variables explicatives décrivant divers
aspects des maisons. Voici la description des variables :</p>
<ul>
<li><strong><code>Price</code></strong> : Le prix de la maison (en
euros), qui constitue la variable cible pour la prédiction.</li>
<li><strong><code>Area</code></strong> : La superficie totale de la
maison en pieds carrés.</li>
<li><strong><code>Bedrooms</code></strong> : Le nombre de chambres dans
la maison.</li>
<li><strong><code>Bathrooms</code></strong> : Le nombre de salles de
bain dans la maison.</li>
<li><strong><code>Stories</code></strong> : Le nombre d'étages dans la
maison.</li>
<li><strong><code>Mainroad</code></strong> : Indique si la maison est
connectée à une route principale (<strong>Yes/No</strong>).</li>
<li><strong><code>Guestroom</code></strong> : Indique si la maison
dispose d'une chambre d'amis (<strong>Yes/No</strong>).</li>
<li><strong><code>Basement</code></strong> : Indique si la maison
dispose d'un sous-sol (<strong>Yes/No</strong>).</li>
<li><strong><code>Hotwaterheating</code></strong> : Indique si la maison
est équipée d'un système de chauffage à eau chaude
(<strong>Yes/No</strong>).</li>
<li><strong><code>Airconditioning</code></strong> : Indique si la maison
est équipée d'un système de climatisation
(<strong>Yes/No</strong>).</li>
<li><strong><code>Parking</code></strong> : Le nombre d'emplacements de
stationnement disponibles dans la maison.</li>
<li><strong><code>Prefarea</code></strong> : Indique si la maison est
située dans une zone préférée (<strong>Yes/No</strong>).</li>
<li><strong><code>Furnishing status</code></strong> : L'état
d'ameublement de la maison (entièrement meublée, semi-meublée ou non
meublée).</li>
<li><strong><code>House Age</code></strong> : L'âge de la maison,
exprimé en années.</li>
</ul>
<h2 id="b-structure-de-la-base-de-données"><span
class="math inline"><em>b</em></span>. Structure de la Base de
Données</h2>
<p>La base de données comprend des variables numériques continues (comme
<code>Price</code>, <code>Area</code>, <code>House Age</code>, et
<code>Parking</code>), ainsi que des variables catégoriques binaires ou
multinomiales (par exemple, <code>Mainroad</code>,
<code>Guestroom</code>, <code>Furnishing status</code>). Cette diversité
de variables permet d'explorer divers aspects des caractéristiques des
maisons et de construire des modèles de prédiction robustes.</p>
<h2 id="c-analyse-des-variables-et-des-valeurs-manquantes"><span
class="math inline"><em>c</em></span>. Analyse des variables et des
Valeurs Manquantes</h2>
<p>Les variables quantitatives présentent des valeurs manquantes
modérées pour la plupart, à l'exception de l'âge des maisons, quasiment
inexploitable en raison de son taux élevé de valeurs manquantes. Les
moyennes et écart-types des variables comme <code>price</code> et
<code>area</code> indiquent une large dispersion, reflet de la diversité
des biens immobiliers en termes de prix et de superficie.</p>
<p>Les variables catégorielles, telles que <code>mainroad</code>,
<code>guestroom</code>, et <code>basement</code>, contiennent des
valeurs textuelles (oui/non) et comportent peu de valeurs manquantes,
rendant leur gestion plus simple. Une transformation en variables
binaires <span class="math inline">(0/1)</span> faciliterait leur
utilisation dans les modèles prédictifs.</p>
<h2 id="d-conclusion"><span class="math inline"><em>d</em></span>.
Conclusion</h2>
<p>En conclusion, le jeu de données dispose d’informations suffisantes
et variées pour entraîner des modèles de prédiction des prix des
maisons. Néanmoins, certaines étapes de prétraitement sont essentielles,
notamment la gestion des valeurs manquantes (les colonnes avec peu de
valeurs manquantes peuvent être imputées statistiquement, tandis que la
colonne <code>houseage</code> est quasi vide et pourrait être exclue),
le formatage des variables, et l’encodage des caractéristiques
catégorielles. Une fois ces transformations effectuées, les données
seront prêtes pour des analyses et des modélisations plus poussées.</p>
<h1 id="iii-exploration-et-préparation-des-données"><span
class="math inline"><em>I</em><em>I</em><em>I</em></span>. Exploration
et Préparation des Données</h1>
<p>L’exploration des données est une étape cruciale dans tout projet de
data science, car elle permet de mieux comprendre la structure et les
particularités du jeu de données. Cette phase vise à examiner les
caractéristiques des variables, à identifier les tendances générales et
les relations éventuelles entre les variables explicatives et la
variable cible. Pour le jeu de données de prédiction des prix des
maisons, l’exploration des données inclura des analyses univariées et
multivariées, permettant de visualiser la distribution des variables, de
détecter des anomalies ou valeurs extrêmes, et de vérifier la présence
de valeurs manquantes. Cette analyse approfondie fournit ainsi les bases
pour décider des étapes de prétraitement nécessaires, telles que le
nettoyage des données, le formatage des variables et la transformation
des caractéristiques. Une bonne compréhension des données dès le départ
est essentielle pour construire des modèles prédictifs robustes et
efficaces.</p>
<h2 id="nettoyage-et-formatage"><strong>Nettoyage et
formatage</strong></h2>
<p>La phase de traitement des données est essentielle dans tout projet
de machine learning, car elle garantit la qualité et la cohérence des
données en entrée. L’une des étapes fondamentales de cette phase est la
gestion des valeurs manquantes. Les valeurs manquantes, si elles sont
ignorées, peuvent nuire aux performances des modèles en introduisant des
biais ou en réduisant la représentativité des données. Dans ce contexte,
différentes méthodes d’imputation ont été choisies pour remplir les
valeurs manquantes, en fonction de la nature des données et de leur
distribution.</p>
<p>Pour les variables quantitatives, nous avons opté pour l’imputation
par la moyenne ou la médiane. La moyenne est utilisée lorsqu’une
distribution est relativement symétrique, tandis que la médiane est
privilégiée pour les variables susceptibles de contenir des valeurs
extrêmes, car elle est moins influencée par celles-ci. En ce qui
concerne les variables catégorielles, l’imputation par le mode (valeur
la plus fréquente) est retenue pour maintenir la distribution
représentative des catégories. Enfin, les colonnes contenant un nombre
excessif de valeurs manquantes sont supprimées pour éviter des biais
trop importants.</p>
<p>Ces choix méthodologiques permettent d’obtenir un jeu de données
complet et équilibré, prêt pour la modélisation.</p>
<p>Pour assurer la qualité et la cohérence des données utilisées dans
notre modélisation, nous avons développé une fonction de nettoyage et
d’imputation. Cette fonction gère les valeurs manquantes en appliquant
des méthodes adaptées citées ci-haut.</p>
</div>
<div class="cell code" data-execution_count="3">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nettoyage et imputation des valeurs manquantes</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_data(data):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Nettoie, formate et gère les valeurs manquantes dans les données pour la modélisation.</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">        data (pd.DataFrame): Le DataFrame contenant les données brutes.</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">        pd.DataFrame: Le DataFrame nettoyé et prêt pour la modélisation.</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Formatage des noms de colonnes</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    data.columns <span class="op">=</span> [col.lower().replace(<span class="st">&quot; &quot;</span>, <span class="st">&quot;_&quot;</span>) <span class="cf">for</span> col <span class="kw">in</span> data.columns]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Imputation pour les colonnes quantitatives (moyenne ou médiane)</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    numeric_imputations <span class="op">=</span> {</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;price&quot;</span>: <span class="st">&quot;mean&quot;</span>,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;area&quot;</span>: <span class="st">&quot;mean&quot;</span>,</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;bedrooms&quot;</span>: <span class="st">&quot;median&quot;</span>,</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;bathrooms&quot;</span>: <span class="st">&quot;median&quot;</span>,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;stories&quot;</span>: <span class="st">&quot;median&quot;</span>,</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;parking&quot;</span>: <span class="st">&quot;median&quot;</span>,</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col, method <span class="kw">in</span> numeric_imputations.items():</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> col <span class="kw">in</span> data.columns:</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> method <span class="op">==</span> <span class="st">&quot;mean&quot;</span>:</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>                data[col] <span class="op">=</span> data[col].fillna(data[col].mean())</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> method <span class="op">==</span> <span class="st">&quot;median&quot;</span>:</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                data[col] <span class="op">=</span> data[col].fillna(data[col].median())</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Suppression de la colonne `houseage` qui a trop de valeurs manquantes</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&quot;houseage&quot;</span> <span class="kw">in</span> data.columns:</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.drop(columns<span class="op">=</span>[<span class="st">&quot;houseage&quot;</span>])</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Imputation pour les colonnes catégorielles (mode)</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    categorical_cols <span class="op">=</span> [</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;mainroad&quot;</span>, <span class="st">&quot;guestroom&quot;</span>, <span class="st">&quot;basement&quot;</span>,</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;hotwaterheating&quot;</span>, <span class="st">&quot;air_conditioning&quot;</span>,</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;prefarea&quot;</span>, <span class="st">&quot;furnishing_status&quot;</span>,</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> categorical_cols:</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> col <span class="kw">in</span> data.columns:</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>            data[col] <span class="op">=</span> data[col].fillna(data[col].mode()[<span class="dv">0</span>])</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Application du  nettoyage et de l&#39;imputation au DataFrame</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>df_clean <span class="op">=</span> clean_data(df)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="co">#print(df_clean)</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_clean.info()) </span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 809 entries, 0 to 808
Data columns (total 13 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   price              809 non-null    float64
 1   area               809 non-null    float64
 2   bedrooms           809 non-null    float64
 3   bathrooms          809 non-null    float64
 4   stories            809 non-null    float64
 5   mainroad           809 non-null    object 
 6   guestroom          809 non-null    object 
 7   basement           809 non-null    object 
 8   hotwaterheating    809 non-null    object 
 9   air_conditioning   809 non-null    object 
 10  parking            809 non-null    float64
 11  prefarea           809 non-null    object 
 12  furnishing_status  809 non-null    object 
dtypes: float64(6), object(7)
memory usage: 82.3+ KB
None
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Les données sont maintenant complètes et bien formatées, comme le
montrent les <span class="math inline">809</span> valeurs non nulles
présentes pour chacune des <span class="math inline">13</span> variables
(colonnes). Toutes les valeurs manquantes ont été imputées ou les
variables non exploitables ont été supprimées, ce qui garantit la
qualité et la cohérence du jeu de données. Avec un format standardisé
pour les colonnes numériques et catégorielles, les données sont prêtes à
être utilisées pour l’analyse et la modélisation de nos données.</p>
</div>
<section
id="iv-analyse-descriptive-des-variables-de-différents-modèles-à-estimer-à-partir-du-jeux-de-données-recueillis"
class="cell markdown">
<h1><span class="math inline"><em>I</em><em>V</em></span>. Analyse
descriptive des variables de différents modèles à estimer à partir du
jeux de données recueillis.</h1>
<p>Pour mieux comprendre les caractéristiques du jeu de données et les
relations potentielles entre les variables explicatives et la variable
cible, nous effectuons une analyse descriptive comprenant une
visualisation univariée et multivariée. L’étude univariée permet
d’explorer la distribution de chaque variable individuellement, tandis
que l’analyse multivariée aide à identifier les corrélations ou
interactions entre les variables. Ces visualisations offrent une
première vue d’ensemble des données et des patterns sous-jacents,
facilitant ainsi les décisions futures pour la modélisation et
l’interprétation des résultats.</p>
<h2 id="1-étude-univariée"><span class="math inline">1</span>. Étude
univariée</h2>
<p><strong>1.1 Variable dépendante (Variable Cible)</strong></p>
<p>Dans cette section, nous analysons la variable cible de notre projet
: <strong>le prix des maisons</strong> (<code>price</code>). Cette
variable quantitative représente la valeur estimée des propriétés dans
notre jeu de données. Comprendre la distribution et les caractéristiques
de cette variable est essentiel, car elle détermine l'objectif de notre
modèle de prédiction. L'analyse univariée de la variable cible permettra
d'identifier des éventuelles anomalies, des valeurs extrêmes, ainsi que
la tendance générale des prix des maisons. Cela facilitera également
l'interprétation des résultats et la construction de modèles
robustes.</p>
</section>
<div class="cell code" data-execution_count="4">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> univariate_statistics(data):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Affiche les statistiques descriptives pour les variables quantitatives et catégorielles.</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">    data (DataFrame): DataFrame contenant les variables.</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">    None</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vérification des variables quantitatives</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    numerical_columns <span class="op">=</span> data.select_dtypes(include<span class="op">=</span>[<span class="st">&#39;float64&#39;</span>, <span class="st">&#39;int64&#39;</span>]).columns</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(numerical_columns) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Statistiques univariées pour les variables quantitatives :&quot;</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(data[numerical_columns].describe())</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Aucune variable quantitative trouvée dans le DataFrame.&quot;</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vérification des variables catégorielles</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    categorical_columns <span class="op">=</span> data.select_dtypes(include<span class="op">=</span><span class="st">&#39;object&#39;</span>).columns</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(categorical_columns) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Statistiques univariées pour les variables catégorielles :&quot;</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> col <span class="kw">in</span> categorical_columns:</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> :&quot;</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(data[col].value_counts())</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Aucune variable catégorielle trouvée dans le DataFrame.&quot;</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> univariate_visualization(data, numerical_columns, categorical_columns<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Affiche les visualisations univariées pour chaque variable quantitative et catégorielle.</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co">    data (DataFrame): DataFrame contenant les données.</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="co">    numerical_columns (list): Liste des colonnes numériques à visualiser.</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="co">    categorical_columns (list, optional): Liste des colonnes catégorielles à visualiser. Par défaut, None.</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co">    None</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> categorical_columns <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>        categorical_columns <span class="op">=</span> []</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Définition des différentes palettes de couleurs</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    color_palettes <span class="op">=</span> [<span class="st">&#39;viridis&#39;</span>, <span class="st">&#39;plasma&#39;</span>, <span class="st">&#39;inferno&#39;</span>, <span class="st">&#39;magma&#39;</span>, <span class="st">&#39;cividis&#39;</span>]</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    categorical_palette <span class="op">=</span> <span class="st">&quot;Set2&quot;</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualisation des variables quantitatives</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(numerical_columns) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(numerical_columns):</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> sns.color_palette(color_palettes[i <span class="op">%</span> <span class="bu">len</span>(color_palettes)])[<span class="dv">2</span>]</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Histogramme</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>            plt.subplot(<span class="bu">len</span>(numerical_columns), <span class="dv">2</span>, <span class="dv">2</span> <span class="op">*</span> i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>            sns.histplot(data[col], kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>color)</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="ss">f&quot;Distribution de </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">&quot;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>            plt.xlabel(col, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>            plt.ylabel(<span class="st">&quot;Count&quot;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Boxplot</span></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>            plt.subplot(<span class="bu">len</span>(numerical_columns), <span class="dv">2</span>, <span class="dv">2</span> <span class="op">*</span> i <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>            sns.boxplot(x<span class="op">=</span>data[col], color<span class="op">=</span>color)</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="ss">f&quot;Boxplot de </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">&quot;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>            plt.xlabel(col, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Aucune variable quantitative à visualiser.&quot;</span>)</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualisation des variables catégorielles</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(categorical_columns) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, col <span class="kw">in</span> <span class="bu">enumerate</span>(categorical_columns):</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>            plt.subplot(<span class="bu">len</span>(categorical_columns), <span class="dv">1</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>            sns.countplot(data<span class="op">=</span>data, x<span class="op">=</span>col, hue<span class="op">=</span>col, palette<span class="op">=</span>categorical_palette, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="ss">f&quot;Distribution de </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">&quot;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>            plt.xlabel(col, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>            plt.ylabel(<span class="st">&quot;Count&quot;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Aucune variable catégorielle à visualiser.&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="5">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>univariate_statistics(df_clean[[<span class="st">&#39;price&#39;</span>]])</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>univariate_visualization(df_clean, [<span class="st">&#39;price&#39;</span>], [])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Statistiques univariées pour les variables quantitatives :
              price
count  8.090000e+02
mean   5.406437e+06
std    2.190206e+06
min    1.750000e+06
25%    3.640000e+06
50%    4.900000e+06
75%    7.140000e+06
max    1.330000e+07
Aucune variable catégorielle trouvée dans le DataFrame.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/8a69c134800d93ebedccfd480553847ec303dd45.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Aucune variable catégorielle à visualiser.
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>La distribution des prix est asymétrique, avec une forte
concentration autour de la moyenne (<span
class="math inline">5, 4</span> millions), mais plusieurs valeurs
extrêmes au-delà de <span class="math inline">10</span> millions. Le
boxplot confirme cette asymétrie et montre des valeurs aberrantes, ce
qui suggère une variabilité significative dans les prix des maisons.
Cette dispersion importante pourrait être due à des propriétés de
différentes tailles ou dans des emplacements variés.</p>
<p><strong>1.2. Variables explicatives</strong></p>
<p>Les variables explicatives sont au nombre de <span
class="math inline">12</span> : Cinq variables continues ('area',
'bedrooms', 'bathrooms', 'stories', 'parking') et <span
class="math inline">7</span> variables catégorielles ('mainroad',
'guestroom', 'basement', 'hotwaterheating', 'air_conditioning',
'prefarea', 'furnishing_status').</p>
<p>Le tableau suivant présente leurs statistiques descriptives :</p>
</div>
<div class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Liste des colonnes numériques et catégorielles</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> [<span class="st">&#39;area&#39;</span>, <span class="st">&#39;bedrooms&#39;</span>, <span class="st">&#39;bathrooms&#39;</span>, <span class="st">&#39;stories&#39;</span>, <span class="st">&#39;parking&#39;</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> [<span class="st">&#39;mainroad&#39;</span>, <span class="st">&#39;guestroom&#39;</span>, <span class="st">&#39;basement&#39;</span>, <span class="st">&#39;hotwaterheating&#39;</span>, <span class="st">&#39;air_conditioning&#39;</span>, <span class="st">&#39;prefarea&#39;</span>, <span class="st">&#39;furnishing_status&#39;</span>]</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des statistiques et visualisations</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>univariate_statistics(df_clean[numerical_columns <span class="op">+</span> categorical_columns])</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>univariate_visualization(df_clean, numerical_columns, categorical_columns)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#df.describe()  # Affiche des statistiques descriptives pour chaque colonne.</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Statistiques univariées pour les variables quantitatives :
               area    bedrooms   bathrooms     stories     parking
count    809.000000  809.000000  809.000000  809.000000  809.000000
mean    5482.997481    3.046972    1.457355    1.936959    0.829419
std     2182.793075    0.731382    0.664498    0.942522    0.866354
min     1650.000000    1.000000    1.000000    1.000000    0.000000
25%     3700.000000    3.000000    1.000000    1.000000    0.000000
50%     5400.000000    3.000000    1.000000    2.000000    1.000000
75%     6600.000000    3.000000    2.000000    2.000000    2.000000
max    16200.000000    6.000000    4.000000    4.000000    3.000000

Statistiques univariées pour les variables catégorielles :

mainroad :
mainroad
yes    719
no      90
Name: count, dtype: int64

guestroom :
guestroom
no     644
yes    165
Name: count, dtype: int64

basement :
basement
no     529
yes    280
Name: count, dtype: int64

hotwaterheating :
hotwaterheating
no     759
yes     50
Name: count, dtype: int64

air_conditioning :
air_conditioning
no     496
yes    313
Name: count, dtype: int64

prefarea :
prefarea
no     605
yes    204
Name: count, dtype: int64

furnishing_status :
furnishing_status
semi-furnished    339
unfurnished       238
furnished         224
FURNISHED           4
Furnished           4
Name: count, dtype: int64
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/9481b0326a9dbf405435675d6a3f496a4cdf966b.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/1de497fad7c5d9f7875738bf5979077834f14e78.png" /></p>
</div>
</div>
<div class="cell markdown">
<h3 id="a-analyse-et-interprétation-des-sorties"><span
class="math inline"><em>a</em></span>. Analyse et Interprétation des
Sorties</h3>
<ol>
<li><strong>Variables Quantitatives :</strong>
<ul>
<li><strong>Superficie (area)</strong> : La distribution de la
superficie présente également une asymétrie, avec un pic autour de <span
class="math inline">5000</span> pieds carrés et quelques valeurs très
élevées allant jusqu'à <span class="math inline">16200</span> pieds
carrés. Le boxplot révèle plusieurs valeurs extrêmes, indiquant une
hétérogénéité marquée dans la taille des propriétés. Cette variabilité
est typique des marchés immobiliers où les biens peuvent varier de
manière significative en fonction de leur emplacement et de leurs
caractéristiques.</li>
<li><strong>Chambres (bedrooms)</strong> : La distribution est
principalement concentrée autour de <span class="math inline">3</span>
chambres, avec quelques maisons ayant jusqu'à <span
class="math inline">6</span> chambres, marquées comme valeurs extrêmes
dans le boxplot. Cela montre que la plupart des maisons sont de taille
moyenne, mais quelques-unes sont de grande taille avec plus de
chambres.</li>
<li><strong>Salles de bain (bathrooms)</strong> : La majorité des
maisons ont <span class="math inline">1</span> ou <span
class="math inline">2</span> salles de bain, avec des cas rares ayant
jusqu'à <span class="math inline">4</span> salles de bain. Cette
répartition est similaire à celle des chambres, montrant une tendance
vers des maisons de taille moyenne.</li>
<li><strong>Étages (stories)</strong> : La distribution indique que la
majorité des maisons ont <span class="math inline">1</span> ou <span
class="math inline">2</span> étages, avec quelques valeurs extrêmes pour
les maisons de <span class="math inline">4</span> étages, visibles dans
le boxplot. Cela peut indiquer des styles de maisons différents, par
exemple, des maisons de ville avec plusieurs étages.</li>
<li><strong>Parking</strong> : La plupart des maisons disposent d'une
place de parking, bien que certaines en possèdent jusqu'à 3. La
répartition montre une majorité avec peu de places, suggérant une
variation en fonction des caractéristiques ou de la localisation des
maisons.</li>
</ul></li>
<li><strong>Variables Catégorielles :</strong>
<ul>
<li><strong>Mainroad, Guestroom, Basement, Hotwaterheating, Air
Conditioning, Prefarea :</strong> La majorité des maisons sont situées
sur des routes principales, sans chambre d’invités, sans sous-sol, ni
chauffage à eau chaude. Peu de maisons sont équipées de climatisation.
Les barres de distribution montrent un déséquilibre important pour ces
caractéristiques, avec la plupart des valeurs concentrées sur "yes" ou
"no". Cela peut influencer les caractéristiques principales de
l’échantillon, notamment sur les commodités et l’accessibilité.</li>
<li><strong>Furnishing Status</strong> : La majorité des maisons sont
semi-meublées ou non meublées. Il existe cependant plusieurs variations
d'orthographe (<code>furnished</code>, <code>FURNISHED</code>,
<code>Furnished</code>), indiquant un besoin de standardisation. Les
barres montrent une distribution variée pour le statut d’ameublement,
suggérant une diversité dans l’aménagement des biens.</li>
</ul></li>
</ol>
<h3 id="b-conclusion"><span class="math inline"><em>b</em></span>.
Conclusion</h3>
<p>Les analyses révèlent une diversité marquée dans les caractéristiques
des maisons, en particulier pour les variables quantitatives comme le
prix et la superficie, avec des valeurs extrêmes pour certaines d'entre
elles. Les distributions et boxplots montrent des asymétries et des
valeurs aberrantes, qui pourraient influencer les analyses futures. Les
variables catégorielles révèlent des déséquilibres dans certaines
caractéristiques (comme la présence de climatisation, de sous-sol,
etc.), ce qui pourrait refléter les préférences ou les contraintes du
marché. Enfin, des corrections pour uniformiser les valeurs de certaines
catégories (<code>furnishing_status</code>) seront nécessaires pour
garantir la cohérence des données avant la modélisation.</p>
</div>
<section id="2-étude-bivariée" class="cell markdown">
<h2><span class="math inline">2</span>. Étude bivariée</h2>
<p>Vues les natures de nos variables (qualitatives et quantitatives),
les tests de dépendance de Khi-deux et de comparaison des moyennes nous
permettront de vérifier l’existence ou non d’une liaison entre nos
variables explicatives et la variable expliquée <code>price</code>.</p>
<p><strong><span class="math inline">2.1</span>. Test de dépendance de
Khi-deux</strong></p>
<p>Ce type de test n’est valable que pour les variables explicatives et
la variable cible toutes <strong>qualitatives</strong>. Pour ce test,
considérons les hypothèses de test suivantes : <span
class="math display">$$
\begin{cases}
H_0 : \text{la variable } X_i \text{ et le prix de la maison ne sont pas
significativement liés} \\
H_1 : \text{la variable } X_i \text{ et le prix de la maison sont
significativement liés}
\end{cases}
$$</span></p>
<p>Où <span class="math inline"><em>X</em><sub><em>i</em></sub></span>
désigne la <span
class="math inline"><em>i</em><sup><em>è</em><em>m</em><em>e</em></sup></span>
variable explicative qualitative <span
class="math inline">(<em>i</em>=1,2,···,7)</span> de notre liste de
variables explicatives.</p>
<p>Le seuil de significativité retenu pour ce test est de <span
class="math inline">5%</span>. Le seuil de significativité retenu pour
ce test est de <span class="math inline">5%</span>. Ainsi, si la
<strong>p-value</strong> associée à la statistique de Khi-deux est
supérieure au seuil retenu, alors on rejettera l’hypothèse <span
class="math inline"><em>H</em><sub>1</sub></span> et on conclura que les
deux variables ne sont pas liées ; dans le cas contraire, on rejettera
l’hypothèse <span class="math inline"><em>H</em><sub>0</sub></span> et
on dira qu’elles sont liées.</p>
<p>L'autre critère de significativité est de comparer les
<strong>Statistiques de Chi-<span class="math inline">2</span></strong>
. Ainsi,</p>
<ul>
<li>Plus la valeur de la statistique de Chi-<span
class="math inline">2</span> est élevée, plus il est probable qu'il
existe une association significative entre la variable catégorielle et
la variable cible.</li>
<li>Une valeur de Chi-<span class="math inline">2</span> élevée indique
une forte divergence entre les fréquences observées et les fréquences
attendues, ce qui suggère que la variable catégorielle influence la
variable cible.</li>
</ul>
<p>Dans cette étude, il s’agit de faire des tableaux croisés et des
tests d’indépendance pour les variables qualitatives suivantes :</p>
<ul>
<li><strong>mainroad</strong> (route principale)</li>
<li><strong>guestroom</strong> (chambre d’invités)</li>
<li><strong>basement</strong> (sous-sol)</li>
<li><strong>hotwaterheating</strong> (chauffage à eau chaude)</li>
<li><strong>air_conditioning</strong> (climatisation)</li>
<li><strong>prefarea</strong> (zone préférée)</li>
<li><strong>furnishing_status</strong> (statut d’ameublement)</li>
</ul>
<p>En appliquant le test de Khi-deux pour chacune de ces variables
explicatives qualitatives, nous pourrons déterminer celles qui sont
significativement corrélées avec le prix de la maison. Si la p-value est
inférieure à <span class="math inline">5%</span>, cela signifie que la
variable explicative est significativement liée à la variable cible, et
elle sera considérée comme pertinente pour notre modèle de
prédiction.</p>
<p>Le code suivant permet de faire un tel test.</p>
</section>
<div class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test de Khi-deux pour les variables catégorielles</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> [<span class="st">&#39;mainroad&#39;</span>, <span class="st">&#39;guestroom&#39;</span>, <span class="st">&#39;basement&#39;</span>, <span class="st">&#39;hotwaterheating&#39;</span>, <span class="st">&#39;air_conditioning&#39;</span>, <span class="st">&#39;prefarea&#39;</span>, <span class="st">&#39;furnishing_status&#39;</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> categorical_columns:</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    contingency_table <span class="op">=</span> pd.crosstab(df_clean[col], df_clean[<span class="st">&#39;price&#39;</span>] <span class="op">&gt;</span> df_clean[<span class="st">&#39;price&#39;</span>].median())</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    chi2, p, dof, ex <span class="op">=</span> chi2_contingency(contingency_table)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f&quot;Test de Khi-deux pour {col}:&quot;)</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f&quot;Chi2 = {chi2}, p-value = {p}\n&quot;)</span></span></code></pre></div>
</div>
<div class="cell markdown">
<p><strong>Affichage et Analyse des Résultats :</strong></p>
<table>
<colgroup>
<col style="width: 28%" />
<col style="width: 17%" />
<col style="width: 25%" />
<col style="width: 28%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Chi-2</th>
<th>p-value</th>
<th>Significativité</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>mainroad</strong></td>
<td><span class="math inline">60.88</span></td>
<td><span class="math inline">6.07<em>e</em> − 15</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>guestroom</strong></td>
<td><span class="math inline">76.52</span></td>
<td><span class="math inline">2.18<em>e</em> − 18</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>basement</strong></td>
<td><span class="math inline">24.38</span></td>
<td><span class="math inline">7.90<em>e</em> − 07</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>hotwaterheating</strong></td>
<td><span class="math inline">11.96</span></td>
<td><span class="math inline">5.45<em>e</em> − 04</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>air_conditioning</strong></td>
<td><span class="math inline">158.26</span></td>
<td><span class="math inline">2.71<em>e</em> − 36</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>prefarea</strong></td>
<td><span class="math inline">87.87</span></td>
<td><span class="math inline">6.97<em>e</em> − 21</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>furnishing_status</strong></td>
<td><span class="math inline">45.65</span></td>
<td><span class="math inline">2.92<em>e</em> − 09</span></td>
<td><strong>Significatif</strong></td>
</tr>
</tbody>
</table>
<p>Après analyse de nos résultats, on retient que :</p>
<ul>
<li><strong>Toutes les variables catégorielles analysées</strong> sont
<strong>significativement corrélées</strong> avec la variable cible, car
leurs p-values sont toutes inférieures à <span
class="math inline">0.05</span>.</li>
<li>Les variables avec des valeurs de Chi-<span
class="math inline">2</span> très élevées, comme
<code>air_conditioning</code>, <code>prefarea</code>, et
<code>guestroom</code>, montrent une <strong>association très
forte</strong> avec la variable cible. Cela indique que ces variables
sont particulièrement importantes pour l’étude et devraient être
incluses par défaut dans notre modèle de prédiction.</li>
</ul>
<p>En résumé, les résultats des tests de Khi-deux confirment que les
variables catégorielles que nous avons analysées sont toutes pertinentes
pour notre étude de prédiction des prix des maisons.</p>
<p>Une autre façon de tester la significativité entre variables
catégorielles est d'utiliser le test ANOVA (Analyse of variance).</p>
<p>Le test ANOVA, tout comme le test de Khi-deux, vise à évaluer
l’association entre une variable catégorielle et la variable cible.
Alors que le test de Khi-deux analyse la dépendance en comparant les
fréquences observées et attendues, le test ANOVA se concentre sur la
comparaison des moyennes entre différentes catégories. Ce test repose
sur les critères suivants :</p>
<ol>
<li><strong>Statistique F de Fisher</strong> :
<ul>
<li>La <strong>statistique F</strong> mesure la proportion de la
variance expliquée par la variable catégorielle par rapport à la
variance non expliquée.</li>
<li>Plus la valeur de F est élevée, plus il est probable qu'il existe
une différence significative entre les moyennes des groupes. Cela
indique que la variable catégorielle influence fortement la variable
cible.</li>
</ul></li>
<li><strong>p-value</strong> :
<ul>
<li>La <strong>p-value</strong> indique la probabilité d'observer un
résultat aussi extrême que celui obtenu, en supposant que l'hypothèse
nulle soit vraie.</li>
<li>Si la p-value est <strong>inférieure à <span
class="math inline">0.05</span></strong>, nous rejetons l’hypothèse
nulle. Cela signifie qu'il existe une différence significative entre les
moyennes des groupes, et la variable catégorielle est significativement
corrélée avec la variable cible.</li>
<li>Si la p-value est <strong>supérieure à <span
class="math inline">0.05</span></strong>, nous n’avons pas suffisamment
de preuves pour rejeter l’hypothèse nulle, et nous considérons que la
variable catégorielle n’est pas significativement corrélée avec la
variable cible.</li>
</ul></li>
</ol>
<p>La fonction suivante permet de réaliser un tel test.</p>
</div>
<div class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> anova_test(data, target, categorical_columns):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Effectue un test ANOVA pour évaluer la corrélation entre les variables catégorielles et la variable cible.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">    data (DataFrame): DataFrame contenant les données.</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">    target (str): Nom de la variable cible.</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">    categorical_columns (list): Liste des variables catégorielles.</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">    None</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> categorical_columns:</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        groups <span class="op">=</span> [data[target][data[col] <span class="op">==</span> level] <span class="cf">for</span> level <span class="kw">in</span> data[col].unique()]</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        f_stat, p_value <span class="op">=</span> stats.f_oneway(<span class="op">*</span>groups)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;ANOVA pour </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> : F-stat = </span><span class="sc">{</span>f_stat<span class="sc">:.2f}</span><span class="ss">, p-value = </span><span class="sc">{</span>p_value<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p_value <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;La variable catégorielle </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> est significativement corrélée avec la variable cible </span><span class="sc">{</span>target<span class="sc">}</span><span class="ss">.</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Aucune corrélation significative entre </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss"> et </span><span class="sc">{</span>target<span class="sc">}</span><span class="ss">.</span><span class="ch">\n</span><span class="ss">&quot;</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple d&#39;utilisation</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> [<span class="st">&#39;mainroad&#39;</span>, <span class="st">&#39;guestroom&#39;</span>, <span class="st">&#39;basement&#39;</span>, <span class="st">&#39;hotwaterheating&#39;</span>, <span class="st">&#39;air_conditioning&#39;</span>, <span class="st">&#39;prefarea&#39;</span>, <span class="st">&#39;furnishing_status&#39;</span>]</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">#anova_test(df_clean, &#39;price&#39;, categorical_columns)</span></span></code></pre></div>
</div>
<div class="cell markdown">
<p>Les résultats et analyses de ce test sont consignés dans le tableau
suivant et confirment toutes les analyses faites précédemment.</p>
<table>
<colgroup>
<col style="width: 28%" />
<col style="width: 18%" />
<col style="width: 24%" />
<col style="width: 28%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>F-stat</th>
<th>p-value</th>
<th>Significativité</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>mainroad</strong></td>
<td><span class="math inline">92.93</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>guestroom</strong></td>
<td><span class="math inline">59.10</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>basement</strong></td>
<td><span class="math inline">26.04</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>hotwaterheating</strong></td>
<td><span class="math inline">23.31</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>air_conditioning</strong></td>
<td><span class="math inline">240.53</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>prefarea</strong></td>
<td><span class="math inline">78.62</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>furnishing_status</strong></td>
<td><span class="math inline">17.63</span></td>
<td><span class="math inline">0.0000</span></td>
<td><strong>Significatif</strong></td>
</tr>
</tbody>
</table>
<p><strong><span class="math inline">2.2</span>. Test de comparaison des
Moyennes</strong></p>
<p>Dans notre projet de prédiction des prix des maisons, nous avons des
variables explicatives quantitatives telles que la superficie de la
maison (<code>area</code>), le nombre de chambres
(<code>bedrooms</code>), le nombre de salles de bain
(<code>bathrooms</code>), le nombre d'étages (<code>stories</code>), et
le nombre de places de parking (<code>parking</code>). Ces types de
tests sont donc plus adaptés pour étudier une dépendance entre chacune
de ces variables avec la variable dépendante <code>price</code>.</p>
<p>Pour cela, considérons les hypothèses de test suivantes :</p>
<p><span class="math display">$$
\begin{cases}
H_0 : \text{la variable } X_i \text{ et le prix de la maison ne sont pas
significativement liés} \\
H_1 : \text{la variable } X_i \text{ et le prix de la maison sont
significativement liés}
\end{cases}
$$</span></p>
<p>Où <span class="math inline"><em>X</em><sub><em>i</em></sub></span>
désigne la <span
class="math inline"><em>i</em><sup><em>è</em><em>m</em><em>e</em></sup></span>
variable explicative quantitative <span
class="math inline">(<em>i</em>=1,2,···,5)</span> de notre liste de
variables explicatives.</p>
<p>Le seuil de significativité retenu pour ce test est de <span
class="math inline">5%</span>. Ainsi, si la p-value associée à la
statistique de comparaison des moyennes est supérieure au seuil retenu,
alors nous rejetons l’hypothèse <span
class="math inline"><em>H</em><sub>1</sub></span> et concluons que les
deux variables ne sont pas liées. Dans le cas contraire, nous rejetons
l’hypothèse <span class="math inline"><em>H</em><sub>0</sub></span> et
affirmons qu’elles sont liées.</p>
<p>Dans cette étude, nous utiliserons des tests de comparaison des
moyennes pour analyser la relation entre les variables explicatives
quantitatives suivantes et la variable cible <code>price</code> :</p>
<ul>
<li><strong>area</strong> (Superficie de la maison)</li>
<li><strong>bedrooms</strong> (Nombre de chambres)</li>
<li><strong>bathrooms</strong> (Nombre de salles de bain)</li>
<li><strong>stories</strong> (Nombre d'étages)</li>
<li><strong>parking</strong> (Nombre de places de parking)</li>
</ul>
<p>En résumé, l’objectif est de vérifier l’association entre chaque
variable explicative quantitative et la variable cible
<code>price</code> afin de déterminer celles qui sont significativement
corrélées au prix des maisons et qui doivent être incluses dans notre
modèle prédictif.</p>
<p>Le code suivant permet de faire un tel test.</p>
</div>
<div class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test t pour comparer les moyennes</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> [<span class="st">&#39;area&#39;</span>, <span class="st">&#39;bedrooms&#39;</span>, <span class="st">&#39;bathrooms&#39;</span>, <span class="st">&#39;stories&#39;</span>, <span class="st">&#39;parking&#39;</span>]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> numerical_columns:</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    group1 <span class="op">=</span> df_clean[df_clean[<span class="st">&#39;price&#39;</span>] <span class="op">&gt;</span> df_clean[<span class="st">&#39;price&#39;</span>].median()][col]</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    group2 <span class="op">=</span> df_clean[df_clean[<span class="st">&#39;price&#39;</span>] <span class="op">&lt;=</span> df_clean[<span class="st">&#39;price&#39;</span>].median()][col]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    t_stat, p_val <span class="op">=</span> ttest_ind(group1, group2)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f&quot;Test t pour {col}:&quot;)</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(f&quot;t-stat = {t_stat}, p-value = {p_val}\n&quot;)</span></span></code></pre></div>
</div>
<div class="cell markdown">
<p><strong>Affichage et nalyse des Résultats :</strong></p>
<table>
<colgroup>
<col style="width: 17%" />
<col style="width: 24%" />
<col style="width: 27%" />
<col style="width: 31%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>t-stat</th>
<th>p-value</th>
<th>Significativité</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>area</strong></td>
<td><span class="math inline">17.07</span></td>
<td><span class="math inline">5.45<em>e</em> − 56</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>bedrooms</strong></td>
<td><span class="math inline">11.54</span></td>
<td><span class="math inline">1.28<em>e</em> − 28</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>bathrooms</strong></td>
<td><span class="math inline">17.44</span></td>
<td><span class="math inline">4.94<em>e</em> − 58</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="even">
<td><strong>stories</strong></td>
<td><span class="math inline">12.67</span></td>
<td><span class="math inline">1.14<em>e</em> − 33</span></td>
<td><strong>Significatif</strong></td>
</tr>
<tr class="odd">
<td><strong>parking</strong></td>
<td><span class="math inline">10.47</span></td>
<td><span class="math inline">4.00<em>e</em> − 24</span></td>
<td><strong>Significatif</strong></td>
</tr>
</tbody>
</table>
<p>Après analyse de nos résultats, on retient que :</p>
<ul>
<li><strong>Toutes les variables quantitatives analysées</strong>
(<code>area</code>, <code>bedrooms</code>, <code>bathrooms</code>,
<code>stories</code>, <code>parking</code>) sont significativement liées
à la variable cible (<code>price</code>), car leurs p-values sont toutes
inférieures à <span class="math inline">0.05</span>.</li>
<li>Les variables avec des valeurs de t-stat élevées, comme
<code>area</code> et <code>bathrooms</code>, montrent une différence
plus prononcée entre les groupes et peuvent être considérées comme ayant
une <strong>association plus forte</strong> avec le prix des
maisons.</li>
</ul>
<p>En résumé, les résultats des tests confirment que toutes les
variables quantitatives considérées sont pertinentes pour l'analyse et
doivent être incluses dans le modèle de prédiction.</p>
<p>Vue la nature quantitatives de ces variables, une autre façon de voir
leur significativité avec la variable cible, est de visualiser leur
matrice de corrélation.</p>
<p>Le code ci-dessous permet d'avoir une telle matrice.</p>
</div>
<div class="cell code" data-execution_count="10">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_correlation_matrix(data):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Affiche la matrice de corrélation pour toutes les variables numériques du DataFrame.</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">    data (DataFrame): DataFrame contenant les données.</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">    DataFrame: Matrice de corrélation.</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sélection des colonnes numériques</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    numerical_columns <span class="op">=</span> data.select_dtypes(include<span class="op">=</span>[<span class="st">&#39;float64&#39;</span>, <span class="st">&#39;int64&#39;</span>]).columns</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcul de la matrice de corrélation</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    corr_matrix <span class="op">=</span> data[numerical_columns].corr()</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Affichage de la heatmap de la matrice de corrélation</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(corr_matrix, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">&#39;coolwarm&#39;</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&quot;Matrice de corrélation des variables numériques&quot;</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> corr_matrix</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Application</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> plot_correlation_matrix(df_clean)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(correlation_matrix)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/ae5dbe4ee555917d6fe955c31d2b1bda5d3bc780.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>              price      area  bedrooms  bathrooms   stories   parking
price      1.000000  0.529523  0.397980   0.615856  0.429652  0.451830
area       0.529523  1.000000  0.182052   0.259114  0.139188  0.369594
bedrooms   0.397980  0.182052  1.000000   0.375922  0.357988  0.198216
bathrooms  0.615856  0.259114  0.375922   1.000000  0.344479  0.277572
stories    0.429652  0.139188  0.357988   0.344479  1.000000  0.150506
parking    0.451830  0.369594  0.198216   0.277572  0.150506  1.000000
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>De l'analyse de cette matrice de corélation, il ressort que :</p>
<ul>
<li>Les variables <strong><code>bathrooms</code></strong>,
<strong><code>area</code></strong>, et
<strong><code>parking</code></strong> montrent une forte corrélation
avec la variable cible <code>price</code>. Elles sont donc des
candidates importantes à inclure dans le modèle de prédiction.</li>
<li>Les autres variables, comme <strong><code>stories</code></strong> et
<strong><code>bedrooms</code></strong>, ont des corrélations modérées
mais restent pertinentes pour l’analyse.</li>
<li>Il n’y a pas de corrélations extrêmement élevées entre les variables
explicatives, ce qui suggère qu'il n'y a pas de multicolinéarité
problématique entre elles.</li>
</ul>
<p>Ces résultats indiquent que la majorité des variables explicatives
sont significativement liées au prix des maisons et qu’elles devraient
être prises en compte dans la modélisation, ce que confirme notre test
de comparaison de moyennes.</p>
</div>
<section id="v-typage-des-variables-pour-la-modélisation"
class="cell markdown">
<h1><span class="math inline"><em>V</em></span>. Typage des variables
pour la Modélisation</h1>
<p>Après avoir exploré les données et identifié les variables
importantes, il est essentiel de s'assurer que toutes les variables sont
prêtes pour l'étape de modélisation. Cette section se concentre sur le
typage et la transformation des variables pour garantir une
compatibilité optimale avec les algorithmes de machine learning.</p>
<p>Pour préparer les données au modèle, il est nécessaire de s'assurer
que toutes les variables sont numériques. Voici les étapes clés que nous
suivons :</p>
<p><strong><span class="math inline">1</span>. Conversion des variables
catégorielles :</strong></p>
<ul>
<li>Les variables <strong>catégorielles</strong> doivent être
transformées en variables numériques . Cela peut être effectué de
plusieurs manières mais dans ce projet, nous utiliserons la méthode de
<em>One-Hot Encoding</em> pour attribuer un entier à chaque
catégorie.</li>
</ul>
<p>La méthode de <em>One-Hot Encoding</em> est une technique de
transformation des variables catégorielles en représentations numériques
sans introduire d’ordre implicite entre les catégories. Contrairement au
Label Encoding, où chaque catégorie est attribuée à un entier unique, le
One-Hot Encoding crée une nouvelle colonne pour chaque catégorie,
contenant une valeur binaire (1 ou 0) indiquant la présence ou l’absence
de cette catégorie. Par exemple, une variable couleur avec les
catégories ["rouge", "bleu", "vert"] sera transformée en trois colonnes
: couleur_rouge, couleur_bleu, et couleur_vert. Cette méthode est
particulièrement utile pour les modèles sensibles à l’échelle ou à
l’ordre des données, comme la régression linéaire, car elle évite
d’attribuer une hiérarchie arbitraire aux catégories. Cependant, elle
peut augmenter significativement la dimensionnalité des données si le
nombre de catégories est élevé.</p>
<p><strong><span class="math inline">2</span>. Conversion des variables
booléennes :</strong></p>
<ul>
<li>Les variables <strong>booléennes</strong> doivent être converties en
entiers (<code>0</code> ou <code>1</code>) au lieu de leurs formats
<code>Yes</code> ou <code>No</code>; <code>True</code> ou
<code>False</code>.</li>
</ul>
<p>Nous utilisons le code suivant pour faire la conversion de nos
variables booléennes en entier.</p>
</section>
<div class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 1 : Nettoyage et encodage One-Hot de &#39;furnishing_status&#39;</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df_clean_copy <span class="op">=</span> df_clean.copy()  <span class="co"># Création d&#39;une copie du DataFrame original</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>df_clean_copy[<span class="st">&#39;furnishing_status&#39;</span>] <span class="op">=</span> df_clean_copy[<span class="st">&#39;furnishing_status&#39;</span>].<span class="bu">str</span>.strip().<span class="bu">str</span>.lower()  <span class="co"># Nettoyage des valeurs : tout en minuscules et suppression des espaces</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Encodage fictif (one-hot encoding) pour la colonne furnishing_status</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>df_clean_copy <span class="op">=</span> pd.get_dummies(df_clean_copy, columns<span class="op">=</span>[<span class="st">&#39;furnishing_status&#39;</span>], prefix<span class="op">=</span><span class="st">&#39;furnishing_status&#39;</span>, drop_first<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Conversion explicite des colonnes fictives en entier</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>furnishing_status_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> df_clean_copy.columns <span class="cf">if</span> <span class="st">&#39;furnishing_status_&#39;</span> <span class="kw">in</span> col]</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>df_clean_copy[furnishing_status_columns] <span class="op">=</span> df_clean_copy[furnishing_status_columns].astype(<span class="bu">int</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 2 : Conversion des colonnes booléennes contenant &#39;yes&#39;/&#39;no&#39; ou True/False</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>columns_to_map <span class="op">=</span> [<span class="st">&#39;mainroad&#39;</span>, <span class="st">&#39;guestroom&#39;</span>, <span class="st">&#39;basement&#39;</span>, <span class="st">&#39;hotwaterheating&#39;</span>, <span class="st">&#39;air_conditioning&#39;</span>, <span class="st">&#39;prefarea&#39;</span>]</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Conversion des valeurs booléennes (&#39;yes&#39; -&gt; 1, &#39;no&#39; -&gt; 0) pour chaque colonne spécifiée</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> columns_to_map:</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    df_clean_copy[col] <span class="op">=</span> df_clean_copy[col].<span class="bu">map</span>({<span class="st">&#39;yes&#39;</span>: <span class="dv">1</span>, <span class="st">&#39;no&#39;</span>: <span class="dv">0</span>, <span class="va">True</span>: <span class="dv">1</span>, <span class="va">False</span>: <span class="dv">0</span>}).fillna(<span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 3 : Vérification des résultats</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des 5 premières lignes après les transformations</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Aperçu des données après encodage fictif et conversion des variables booléennes : </span><span class="ch">\n\n</span><span class="ss">&quot;</span>, df_clean_copy.head())</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Comptage des occurrences de 1 et 0 pour les colonnes booléennes</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co">#for col in columns_to_map:</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a> <span class="co">#   counts = df_clean_copy[col].value_counts()</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="co">#  print(f&quot;Occurrences de 1 et 0 dans la colonne &#39;{col}&#39; :&quot;)</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>   <span class="co"># print(counts)</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(&quot;-&quot; * 30)</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérification des colonnes encodées fictivement</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="co">#print(f&quot;Aperçu des colonnes encodées pour &#39;furnishing_status&#39;: \n\n&quot;, df_clean_copy.filter(like=&#39;furnishing_status&#39;).head())</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="co">#print(df_clean_copy)</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="co">#print(df_clean)</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Aperçu des données après encodage fictif et conversion des variables booléennes : 

         price    area  bedrooms  bathrooms  stories  mainroad  guestroom  \
0   4543000.0  4990.0       4.0        2.0      2.0         1          1   
1   8080940.0  7000.0       3.0        2.0      4.0         1          0   
2   8750000.0  4321.0       3.0        2.0      2.0         1          0   
3   1890000.0  1700.0       3.0        1.0      2.0         1          0   
4  12215000.0  7500.0       4.0        2.0      2.0         1          0   

   basement  hotwaterheating  air_conditioning  parking  prefarea  \
0         1                0                 0      0.0         1   
1         0                0                 1      2.0         0   
2         1                1                 0      2.0         0   
3         0                0                 0      0.0         0   
4         1                0                 1      3.0         1   

   furnishing_status_furnished  furnishing_status_semi-furnished  \
0                            1                                 0   
1                            1                                 0   
2                            1                                 0   
3                            0                                 0   
4                            1                                 0   

   furnishing_status_unfurnished  
0                              0  
1                              0  
2                              0  
3                              1  
4                              0  
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong><span class="math inline">3</span>. Validation des Types
:</strong></p>
<ul>
<li>Une fois les conversions effectuées, vérifions que toutes les
colonnes ont des types numériques (<code>int64</code> ou
<code>float64</code>).</li>
</ul>
</div>
<div class="cell code" data-execution_count="12">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>data_prix <span class="op">=</span> df_clean_copy.copy()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_prix.dtypes)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>price                               float64
area                                float64
bedrooms                            float64
bathrooms                           float64
stories                             float64
mainroad                              int64
guestroom                             int64
basement                              int64
hotwaterheating                       int64
air_conditioning                      int64
parking                             float64
prefarea                              int64
furnishing_status_furnished           int64
furnishing_status_semi-furnished      int64
furnishing_status_unfurnished         int64
dtype: object
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>En conclusion, le typage des variables a permis de transformer
efficacement toutes les colonnes catégorielles et booléennes en données
numériques adaptées aux modèles de machine learning. La méthode One-Hot
Encoding a été utilisée pour encoder les catégories non ordonnées, comme
furnishing_status, tandis que les colonnes booléennes contenant des
valeurs telles que yes/no ou True/False ont été converties en valeurs
binaires (<span class="math inline">1</span> et <span
class="math inline">0</span>). Ces transformations garantissent une
table uniformisée, exclusivement composée de données numériques, prête
pour l’entraînement des modèles. La table finale, qui servira de base
pour les modélisations et les analyses, a été nommée
<code>data_prix</code> pour refléter son rôle central dans la prédiction
des prix des maisons.</p>
<h1 id="vi-modélisation"><span
class="math inline"><em>V</em><em>I</em></span>. Modélisation</h1>
<p>La phase de modélisation est une étape clé dans le projet de
prédiction des prix des maisons. Elle consiste à construire et évaluer
différents modèles de régression, en adoptant une approche progressive
allant des modèles simples à des modèles plus complexes et sophistiqués.
L’objectif principal est de comprendre comment les différentes méthodes
permettent de capturer les relations entre les caractéristiques
explicatives et la variable cible (price) tout en améliorant les
performances de prédiction. Nous commencerons par un modèle baseline
pour établir un point de référence, puis nous développerons des modèles
de régression linéaire pour exploiter les relations linéaires entre les
variables. Enfin, nous explorerons des modèles ensemblistes, tels que
les Random Forests et Gradient Boosting, qui permettent de capter des
relations plus complexes et non linéaires. Les performances des modèles
seront évaluées à l’aide de métriques comme l’erreur absolue moyenne
(MAE) et le coefficient de détermination <span
class="math inline">(<em>R</em><sup>2</sup>)</span>, tout en examinant
l’impact de la taille des données d’entraînement sur leurs performances.
Les résultats seront analysés à l’aide de graphiques, tels que la
comparaison des distributions des valeurs réelles et prédites, ainsi que
des scatter plots pour visualiser la précision des prédictions. Cette
approche permet non seulement de comparer les modèles, mais également de
mieux comprendre leur comportement et leur adéquation au problème
étudié.</p>
<h2 id="a-validation-croisée"><span
class="math inline"><em>a</em></span>. Validation croisée</h2>
<p>La validation croisée est une méthode essentielle permettant
d'estimer les performances de prédiction d'un modèle à partir des
données disponibles. Elle repose sur un protocole simple en trois étapes
principales :</p>
<ul>
<li>Diviser les données en deux ensembles : un ensemble d’apprentissage
(<em>train</em>) et un ensemble de test (<em>test</em>), tout en
s'assurant d'une répartition cohérente de la variable cible.</li>
<li>Entraîner le modèle sur l’ensemble d’apprentissage
(<em>train</em>).</li>
<li>Estimer les performances du modèle sur l’ensemble de test
(<em>test</em>), avec des exemples non utilisés lors de
l'apprentissage.</li>
</ul>
<p>De cette façon, les données utilisées pour estimer la performance
sont des exemples nouveaux qui n’ont pas été utilisés lors de
l’apprentissage.</p>
<p>Dans ce projet, le jeu de données <code>data_prix</code> a été divisé
en deux sous-ensembles distincts afin de garantir une évaluation fiable
des performances des modèles. L’ensemble d’entraînement, représentant
<span class="math inline">80%</span> des données avec <span
class="math inline">14</span> variables explicatives, sera utilisé pour
construire et ajuster les modèles. L’ensemble de test, représentant les
<span class="math inline">20%</span> restants et comprenant les mêmes
variables explicatives, servira à évaluer les performances des modèles
sur des données nouvelles, non utilisées lors de l’apprentissage. Cette
division permet de simuler un scénario réaliste où le modèle doit faire
des prédictions sur des données inconnues. À noter que la stratification
a été désactivée dans cette division en raison de la présence de classes
rares dans la variable cible, garantissant ainsi une répartition
aléatoire des données entre les deux ensembles.</p>
<p>Dans le cadre de cette validation croisée, nous avons implémenté une
fonction appelée <code>split_data</code> qui permet de diviser
efficacement notre jeu de données en ensembles d’entraînement et de
test, garantissant ainsi une évaluation rigoureuse des performances de
nos modèles tout en limitant les biais liés à la répartition des
données.</p>
</div>
<div class="cell code" data-execution_count="13">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_data(dataframe, target_column, test_ratio<span class="op">=</span><span class="fl">0.2</span>, random_seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Divise les données en ensembles d&#39;entraînement et de test tout en garantissant </span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">    une répartition similaire de la variable cible, si possible.</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Paramètres :</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co">    dataframe : pd.DataFrame</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Le DataFrame contenant les données étiquetées.</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">    target_column : str</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">        Le nom de la colonne cible (la variable à prédire).</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co">    test_ratio : float, optionnel (par défaut = 0.2)</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co">        La proportion des exemples à inclure dans le set de test.</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co">    random_seed : int, optionnel (par défaut = 42)</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co">        La graine pour la randomisation.</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Retourne :</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="co">    X_train : pd.DataFrame</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co">        Variables explicatives pour l&#39;ensemble d&#39;entraînement.</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="co">    y_train : pd.Series</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="co">        Variable cible pour l&#39;ensemble d&#39;entraînement.</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="co">    X_test : pd.DataFrame</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="co">        Variables explicatives pour l&#39;ensemble de test.</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="co">    y_test : pd.Series</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="co">        Variable cible pour l&#39;ensemble de test.</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Séparation des variables explicatives (X) et la variable cible (y)</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> dataframe.drop(columns<span class="op">=</span>[target_column])  <span class="co"># Supprime la colonne cible</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> dataframe[target_column]  <span class="co"># Colonne cible</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vérification si stratification est nécessaire et applicable</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> y.nunique() <span class="op">&gt;</span> <span class="dv">10</span> <span class="kw">or</span> y.value_counts().<span class="bu">min</span>() <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Désactiver la stratification pour une cible continue ou avec classes rares</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        stratify_option <span class="op">=</span> <span class="va">None</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Attention !!!! : Stratification désactivée en raison de classes rares ou d&#39;une variable continue.&quot;</span>)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sinon, appliquer la stratification</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>        stratify_option <span class="op">=</span> y</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Division des données en ensembles d&#39;entraînement et de test</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>    X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>        X, y, test_size<span class="op">=</span>test_ratio, random_state<span class="op">=</span>random_seed, stratify<span class="op">=</span>stratify_option</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_train, y_train, X_test, y_test</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Chargement des données (data_prix représente votre DataFrame final)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>data_prix_train, price_train, data_prix_test, price_test <span class="op">=</span> split_data(data_prix, target_column<span class="op">=</span><span class="st">&#39;price&#39;</span>, test_ratio<span class="op">=</span><span class="fl">0.2</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Préparation des données pour le tableau</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>data_summary <span class="op">=</span> {</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Nom de l&#39;ensemble&quot;</span>: [<span class="st">&quot;data_prix_train&quot;</span>, <span class="st">&quot;data_prix_test&quot;</span>, <span class="st">&quot;price_train&quot;</span>, <span class="st">&quot;price_test&quot;</span>],</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Taille (lignes)&quot;</span>: [data_prix_train.shape[<span class="dv">0</span>], data_prix_test.shape[<span class="dv">0</span>], price_train.shape[<span class="dv">0</span>], price_test.shape[<span class="dv">0</span>]],</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Taille (variables explicatives)&quot;</span>: [data_prix_train.shape[<span class="dv">1</span>], data_prix_test.shape[<span class="dv">1</span>], <span class="st">&quot;-&quot;</span>, <span class="st">&quot;-&quot;</span>]</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Créeation d&#39;un DataFrame pour afficher sous forme de tableau</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>summary_table <span class="op">=</span> pd.DataFrame(data_summary)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage du tableau</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Tailles des ensembles :&quot;</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary_table)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Attention !!!! : Stratification désactivée en raison de classes rares ou d&#39;une variable continue.

Tailles des ensembles :
  Nom de l&#39;ensemble  Taille (lignes) Taille (variables explicatives)
0   data_prix_train              647                              14
1    data_prix_test              162                              14
2       price_train              647                               -
3        price_test              162                               -
</code></pre>
</div>
</div>
<div class="cell markdown">
<h2
id="b-métriques-et-visualisations-pour-lévaluation-des-modèles"><span
class="math inline"><em>b</em></span>. Métriques et Visualisations pour
l'Évaluation des Modèles</h2>
<p>Avant de passer à la mise en place des différents modèles, il est
important de définir un cadre commun pour l’évaluation et l’analyse des
performances. Ce cadre repose sur l’utilisation de métriques
quantitatives et de visualisations graphiques, applicables à tous les
modèles que nous allons développer.</p>
<h3 id="b_1-métriques-dévaluation"><span
class="math inline"><em>b</em><sub>1</sub></span>. Métriques
d’Évaluation</h3>
<p>Nous utiliserons trois métriques principales pour évaluer les
performances des modèles :</p>
<ol>
<li><strong>MAE (Mean Absolute Error)</strong> :
<ul>
<li>Cette métrique mesure l’erreur moyenne absolue entre les valeurs
réelles et prédites.</li>
<li>Elle est intuitive et permet de quantifier directement la précision
moyenne des prédictions.</li>
</ul></li>
<li><strong>RMSE (Root Mean Squared Error)</strong> :
<ul>
<li>Contrairement au MAE, le RMSE pénalise davantage les grandes erreurs
en élevant les écarts au carré avant de les moyenner.</li>
<li>Il est particulièrement utile pour détecter l’impact des valeurs
aberrantes et fournit une mesure dans la même unité que la variable
cible, ce qui le rend facile à interpréter et permet de quantifier
directement l’échelle de l’erreur moyenne. Un écart significatif entre
RMSE et MAE indique la présence de valeurs aberrantes (outliers).</li>
</ul></li>
<li><strong><span class="math inline"><em>R</em><sup>2</sup></span>
(Coefficient de détermination)</strong> :
<ul>
<li>Le <span class="math inline"><em>R</em><sup>2</sup></span> indique
la proportion de variance des valeurs réelles expliquée par le
modèle.</li>
<li>Il est utile pour évaluer globalement dans quelle mesure un modèle
capture les variations des données.</li>
</ul></li>
</ol>
<p>Ces trois métriques offrent une évaluation complète des performances
en combinant précision absolue (MAE), robustesse aux grandes erreurs
(RMSE), et capacité explicative globale <span
class="math inline">(<em>R</em><sup>2</sup>)</span>.</p>
<h3 id="b_2-visualisations-pour-lanalyse-des-modèles"><span
class="math inline"><em>b</em><sub>2</sub></span>. Visualisations pour
l’Analyse des Modèles</h3>
<p>En complément des métriques, des visualisations graphiques seront
utilisées pour analyser les performances des modèles et identifier leurs
limites :</p>
<ol>
<li><strong>Histogramme des distributions des prix réels et
prédits</strong> :
<ul>
<li>Cet histogramme compare la distribution des valeurs réelles avec
celle des valeurs prédites.</li>
<li>Il permet de visualiser si le modèle capture correctement la
dispersion des prix. Une forte divergence entre les deux distributions
reflète les limites du modèle.</li>
</ul></li>
<li><strong>Scatter plot (Prix réels vs Prix prédits)</strong> :
<ul>
<li>Ce graphique montre la relation entre les valeurs réelles et leurs
prédictions.</li>
<li>Idéalement, les points devraient être proches de la ligne idéale
<code>y=x</code>, indiquant des prédictions précises. Toute dispersion
autour de cette ligne reflète les erreurs du modèle.</li>
</ul></li>
<li><strong>Distribution des résidus</strong> :
<ul>
<li>Les résidus sont les différences entre les valeurs réelles et
prédites.</li>
<li>Ce graphique permet d’analyser les biais potentiels du modèle. Une
distribution centrée autour de <span class="math inline">0</span> et
symétrique indique un modèle équilibré, tandis qu'une asymétrie ou une
concentration des résidus signale des problèmes de sous-prédiction ou
sur-prédiction.</li>
</ul></li>
</ol>
<p>Ces visualisations fournissent une compréhension qualitative des
performances des modèles et complètent les métriques quantitatives pour
une analyse plus approfondie.</p>
<p>En adoptant ces métriques et ces graphiques comme base commune, nous
pouvons comparer de manière cohérente les performances des différents
modèles, qu’il s’agisse du modèle baseline ou des modèles plus complexes
à venir.</p>
<h2 id="c-modèle-baseline"><span class="math inline"><em>c</em></span>.
Modèle Baseline</h2>
<p>Le modèle baseline est une étape fondamentale dans tout projet de
machine learning. Il s’agit de construire un modèle simple qui sert de
point de référence pour évaluer les performances des modèles plus
complexes développés ultérieurement. Dans le contexte de ce projet, le
modèle baseline consiste à estimer le prix des maisons en utilisant une
mesure centralisée, comme la moyenne des prix dans l’ensemble
d’entraînement, en fonction du nombre de chambres.</p>
<p>Pour mettre en place ce modèle baseline, nous implémentons un code
permettant de calculer les prédictions basées sur la moyenne des prix
pour chaque nombre de chambres dans l’ensemble d’entraînement.</p>
</div>
<div class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 1 : Calcul du prix moyen par nombre de chambres (baseline)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>baseline_predictions <span class="op">=</span> price_train.groupby(data_prix_train[<span class="st">&#39;bedrooms&#39;</span>]).mean()</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 2 : Prédiction sur l&#39;ensemble de test en utilisant les moyennes de l&#39;ensemble train</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>price_test_predicted <span class="op">=</span> data_prix_test[<span class="st">&#39;bedrooms&#39;</span>].<span class="bu">map</span>(baseline_predictions)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 3 : Évaluation des performances du modèle baseline</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>mae_baseline <span class="op">=</span> mean_absolute_error(price_test, price_test_predicted)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>r2_baseline <span class="op">=</span> r2_score(price_test, price_test_predicted)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>rmse_baseline <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_predicted))</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Évaluation du modèle baseline :&quot;</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MAE (Mean Absolute Error) : </span><span class="sc">{</span>mae_baseline<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE (Root Mean Squared Error) : </span><span class="sc">{</span>rmse_baseline<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R² (Coefficient de détermination) : </span><span class="sc">{</span>r2_baseline<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Évaluation du modèle baseline :
MAE (Mean Absolute Error) : 1632309.57
RMSE (Root Mean Squared Error) : 2043163.18
R² (Coefficient de détermination) : 0.21
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Le modèle baseline affiche des performances limitées avec un MAE de
<span class="math inline">1, 632, 309.57</span>, indiquant une erreur
moyenne absolue importante dans les prédictions des prix des maisons. Le
RMSE de <span class="math inline">2, 043, 163.18</span>, supérieur au
MAE, montre que des écarts significatifs (grandes erreurs) existent dans
les prédictions, ces derniers étant amplifiés par la pénalisation
quadratique du RMSE. Enfin, le <span
class="math inline"><em>R</em><sup>2</sup></span> de <span
class="math inline">0.21</span> révèle que le modèle explique seulement
<span class="math inline">21%</span> de la variance des prix réels, ce
qui souligne sa faible capacité à capturer les relations sous-jacentes
entre les variables explicatives et la cible.</p>
<p><strong>Conclusion</strong> : Ces résultats, bien qu’attendus pour un
modèle simple basé sur des moyennes, confirment les limites du modèle
baseline. Il ne capture pas la complexité des données et sert uniquement
de point de référence minimal pour comparer les performances des modèles
plus avancés.</p>
<p>Pour mieux comprendre les performances du modèle baseline et
identifier ses limites, nous analysons ses prédictions à l’aide de
visualisations comparant les prix réels et prédits, ainsi que la
distribution des résidus à travers le code suivant.</p>
</div>
<div class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison des distributions des valeurs réelles et prédites</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs réelles&#39;</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test_predicted.dropna(), bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs prédites (baseline)&#39;</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Prix des maisons&#39;</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Fréquence&#39;</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparaison des distributions des prix (réels vs prédits)&#39;</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot des valeurs réelles vs prédites</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(price_test, price_test_predicted, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&quot;Prédictions baseline&quot;</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>plt.plot([price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], [price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], <span class="st">&#39;r--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Ligne idéale (y=x)&quot;</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Prix réels&quot;</span>)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Prix prédits&quot;</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Scatter plot : Prix réels vs Prix prédits (Baseline)&quot;</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution des résidus</span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> price_test <span class="op">-</span> price_test_predicted</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>plt.hist(residuals.dropna(), bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">&quot;Résidus&quot;</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;r&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Moyenne des résidus = 0&quot;</span>)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Résidus (Prix réels - Prix prédits)&quot;</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Fréquence&quot;</span>)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Distribution des résidus&quot;</span>)</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/eb6d58f1ae763fa40f56eb07bdff1d07a9061135.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/2bd7922816e2c1369838b8cb9a850d20cc2a0c3f.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/f5d32602b75e6a4aeb2e1828a6348db06cce326e.png" /></p>
</div>
</div>
<div class="cell markdown">
<h3 id="analyse-des-graphiques">Analyse des graphiques</h3>
<ol>
<li><strong>Histogramme des distributions des prix réels et
prédits</strong></li>
</ol>
<p>Cet histogramme met en évidence une grande divergence entre la
distribution des prix réels et celle des prix prédits par le modèle
baseline. Les prix réels sont bien répartis sur une large plage de
valeurs, montrant une forte variabilité, tandis que les prix prédits se
concentrent autour de quelques moyennes spécifiques. Ces pics reflètent
la nature simpliste du modèle baseline, qui calcule une moyenne par
nombre de chambres sans prendre en compte d'autres caractéristiques
pertinentes, comme la superficie, la localisation, ou les équipements.
Cette différence indique que le modèle ne capture pas la complexité des
données et qu'il simplifie excessivement la relation entre les variables
explicatives et la cible.</p>
<ol>
<li><strong>Scatter plot (Prix réels vs Prix prédits)</strong></li>
</ol>
<p>Le scatter plot montre une faible correspondance entre les prix réels
et leurs prédictions. La majorité des points sont éloignés de la ligne
idéale <code>y=x</code>, ce qui indique des erreurs importantes dans les
prédictions. Les prédictions du modèle baseline sont constantes pour
chaque groupe de chambres, ce qui se traduit par des lignes
horizontales. Cela confirme l'incapacité du modèle à capturer la
variabilité des prix réels et à fournir des prédictions précises.</p>
<ol>
<li><strong>Distribution des résidus</strong></li>
</ol>
<p>La distribution des résidus (différences entre les prix réels et les
prix prédits) met en évidence une large dispersion autour de <span
class="math inline">0</span>, avec des écarts importants dans les
résidus positifs et négatifs. Cela indique que le modèle sous-prédit et
sur-prédit de manière significative dans certains cas, sans tendance
claire. Bien que la moyenne des résidus soit proche de <span
class="math inline">0</span>, leur dispersion montre une variabilité
importante que le modèle ne parvient pas à expliquer.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Les trois graphiques montrent clairement que le modèle baseline est
très limité dans sa capacité à capturer les relations complexes entre
les caractéristiques des maisons et leurs prix. Il simplifie
excessivement la tâche en se basant uniquement sur des moyennes par
nombre de chambres, ce qui entraîne des prédictions imprécises et des
erreurs significatives. Ces résultats confirment que le modèle baseline,
bien qu'utile comme point de départ, doit être amélioré avec des
approches plus sophistiquées pour obtenir de meilleures
performances.</p>
</div>
<div class="cell markdown">
<p>Pour aller au-delà des limitations du modèle baseline, nous
introduisons un modèle de régression linéaire, qui vise à établir une
relation linéaire entre les caractéristiques explicatives des maisons et
leurs prix, permettant ainsi de mieux capturer les variations et
d’améliorer la précision des prédictions.</p>
<h2 id="d-modèle-de-regression-linéaire"><span
class="math inline"><em>d</em></span>. Modèle de regression
linéaire</h2>
<p>Le modèle de régression linéaire est une méthode statistique et de
machine learning utilisée pour modéliser la relation entre une variable
cible continue et une ou plusieurs variables explicatives. Il repose sur
l'hypothèse que cette relation peut être exprimée sous la forme d'une
équation linéaire :</p>
<p><span
class="math inline"><em>y</em> = <em>β</em><sub>0</sub> + <em>β</em><sub>1</sub><em>x</em><sub>1</sub> + <em>β</em><sub>2</sub><em>x</em><sub>2</sub> + … + <em>β</em><sub><em>n</em></sub><em>x</em><sub><em>n</em></sub> + <em>ϵ</em></span></p>
<p>où</p>
<ul>
<li>$ \beta_0 $ est l'ordonnée à l'origine (intercept),</li>
<li>$ \beta_i $ sont les coefficients associés aux variables
explicatives $ x_i $,</li>
<li>et $ \epsilon $ représente l'erreur résiduelle.</li>
</ul>
<p>La régression linéaire ajuste ces coefficients pour minimiser
l'erreur entre les valeurs prédites et les valeurs réelles, généralement
en utilisant la méthode des moindres carrés. Ce modèle est apprécié pour
sa simplicité, sa capacité d'interprétation et sa performance dans les
contextes où les relations entre les variables sont approximativement
linéaires. Cependant, il est sensible aux hypothèses sous-jacentes
(comme la normalité des résidus et l'absence de colinéarité) et peut
avoir des performances limitées dans des problèmes non linéaires ou avec
des données complexes.</p>
<p>Le code suivant permet de construire ce modèle dans le cadre de notre
projet en utilisant toutes les variables explicatives de notre jeu de
donnée traité.</p>
</div>
<div class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajout d&#39;une constante pour le biais (intercept) dans le modèle</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>X_train_with_const <span class="op">=</span> sm.add_constant(data_prix_train)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Construire le modèle de régression linéaire avec statsmodels</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>linear_model_stats <span class="op">=</span> sm.OLS(price_train, X_train_with_const).fit()</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Afficher le résumé statistique</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(linear_model_stats.summary())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.702
Model:                            OLS   Adj. R-squared:                  0.695
Method:                 Least Squares   F-statistic:                     114.4
Date:                Mon, 02 Dec 2024   Prob (F-statistic):          1.92e-156
Time:                        21:06:26   Log-Likelihood:                -9963.8
No. Observations:                 647   AIC:                         1.996e+04
Df Residuals:                     633   BIC:                         2.002e+04
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
====================================================================================================
                                       coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------------------------
const                            -2.297e+05   1.92e+05     -1.194      0.233   -6.08e+05    1.48e+05
area                               236.7044     24.856      9.523      0.000     187.894     285.515
bedrooms                          2.055e+05   7.36e+04      2.793      0.005     6.1e+04     3.5e+05
bathrooms                         9.687e+05   8.42e+04     11.508      0.000    8.03e+05    1.13e+06
stories                           3.767e+05   6.06e+04      6.216      0.000    2.58e+05    4.96e+05
mainroad                          6.077e+05   1.63e+05      3.722      0.000    2.87e+05    9.28e+05
guestroom                         3.441e+05    1.3e+05      2.657      0.008    8.98e+04    5.98e+05
basement                          3.157e+05   1.12e+05      2.821      0.005     9.6e+04    5.35e+05
hotwaterheating                    1.15e+06   2.08e+05      5.540      0.000    7.42e+05    1.56e+06
air_conditioning                  9.607e+05   1.12e+05      8.574      0.000    7.41e+05    1.18e+06
parking                           3.647e+05   6.15e+04      5.931      0.000    2.44e+05    4.85e+05
prefarea                          5.969e+05   1.16e+05      5.152      0.000    3.69e+05    8.24e+05
furnishing_status_furnished      -3.154e+04   1.05e+05     -0.301      0.764   -2.37e+05    1.74e+05
furnishing_status_semi-furnished  1.066e+05   8.99e+04      1.185      0.236      -7e+04    2.83e+05
furnishing_status_unfurnished    -3.048e+05   8.82e+04     -3.454      0.001   -4.78e+05   -1.31e+05
==============================================================================
Omnibus:                       49.090   Durbin-Watson:                   1.970
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               92.859
Skew:                           0.487   Prob(JB):                     6.85e-21
Kurtosis:                       4.580   Cond. No.                     4.87e+19
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The smallest eigenvalue is 9.37e-30. This might indicate that there are
strong multicollinearity problems or that the design matrix is singular.
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3
id="analyse-des-coefficients-attribués-à-chaque-caractéristique">Analyse
des coefficients attribués à chaque caractéristique</h3>
<p>Les coefficients estimés par le modèle de régression linéaire
indiquent l'impact de chaque caractéristique sur le prix des maisons,
tout en tenant compte des autres variables. Voici une analyse des
coefficients principaux lorsque nous considérons <code>euros</code>
comme unité monnétaire :</p>
<p><strong><code>area</code> (<span
class="math inline">236.7044 €</span>)</strong> :</p>
<ul>
<li>Ce coefficient positif montre que chaque mètre carré supplémentaire
de surface habitable augmente le prix de la maison de <span
class="math inline">236.70 €</span> en moyenne, toutes les autres
variables étant égales. Ceci reflète l'importance de la superficie dans
la valorisation immobilière.</li>
</ul>
<p><strong><code>bedrooms</code> (<span
class="math inline">205, 500 €</span>)</strong> :</p>
<ul>
<li>Un nombre supplémentaire de chambres contribue à une augmentation
moyenne de <span class="math inline">205, 500 €</span> dans le prix de
la maison, toutes les autres variables étant égales. Ce qui reflète
l'importance des chambres comme critère clé dans l'évaluation des
maisons.</li>
</ul>
<p><strong><code>bathrooms</code> (<span
class="math inline">968, 700 €</span>)</strong> :</p>
<ul>
<li>Ce coefficient positif montre que, toute chose étant égale par
ailleurs, chaque salle de bain supplémentaire ajoute en moyenne <span
class="math inline">968, 700 €</span> au prix de la maison. C'est l'une
des variables les plus influentes, probablement en raison de la valeur
perçue des salles de bain modernes ou multiples.</li>
</ul>
<p><strong><code>stories</code> (<span
class="math inline">376, 700 €</span>)</strong> :</p>
<ul>
<li>Avec ce coefficient positif, toutes les autres variables étant
égales, une maison avec un étage supplémentaire voit son prix augmenter
en moyenne de <span class="math inline">376.700 €</span>. Cela peut
s’expliquer par une préférence pour les maisons à plusieurs niveaux,
offrant plus d’espace sans augmenter l’empreinte au sol.</li>
</ul>
<p><strong><code>mainroad</code> (<span
class="math inline">607, 700 €</span>)</strong> :</p>
<ul>
<li>Une maison située près d'une route principale voit son prix
augmenter significativement, de <span
class="math inline">607, 700 €</span> en moyenne. Cette proximité peut
être perçue comme un avantage en termes d'accessibilité, bien que cela
puisse également avoir des inconvénients (comme le bruit).</li>
</ul>
<p><strong><code>air_conditioning</code> (<span
class="math inline">960, 700 €</span>)</strong> :</p>
<ul>
<li>La présence de la climatisation ajoute en moyenne <span
class="math inline">960, 700 €</span> au prix, soulignant son rôle
important dans le confort des maisons.</li>
</ul>
<p><strong><code>guestroom</code> (<span
class="math inline">344, 100 €</span>)</strong> :</p>
<ul>
<li>La présence d’une chambre d’amis augmente le prix moyen de la maison
de <span class="math inline">344, 100 €</span>. Cela reflète
l'importance accordée à des espaces supplémentaires pour accueillir des
invités ou pour un usage personnel.</li>
</ul>
<p><strong><code>basement</code> (<span
class="math inline">315, 700 €</span>)</strong> :</p>
<ul>
<li>Une maison avec un sous-sol voit son prix augmenter en moyenne de
<span class="math inline">315, 700 €</span>. Les sous-sols sont souvent
considérés comme des espaces polyvalents, ajoutant de la valeur à la
maison.</li>
</ul>
<p><strong><code>hotwaterheating</code> (<span
class="math inline">1.150.000 €</span>)</strong> :</p>
<ul>
<li>La présence d'un système de chauffage à eau chaude est associée à
une augmentation moyenne de <span
class="math inline">1, 150, 000 €</span>. Ce coefficient positif élevé
montre l'importance perçue des équipements modernes pour le confort et
l'efficacité énergétique.</li>
</ul>
<p><strong><code>air_conditioning</code> (<span
class="math inline">960, 700 €</span>)</strong> :</p>
<ul>
<li>La présence de climatisation contribue à une augmentation moyenne de
<span class="math inline">960, 700 €</span> du prix. Cela reflète son
rôle dans le confort, notamment dans les régions où les températures
sont élevées.</li>
</ul>
<p><strong><code>parking</code> (<span
class="math inline">364, 700 €</span>)</strong> :</p>
<ul>
<li>Chaque place de parking supplémentaire augmente le prix de la maison
de <span class="math inline">364, 700 €</span> en moyenne. Les places de
parking sont souvent perçues comme un élément de commodité majeur, en
particulier dans les zones urbaines.</li>
</ul>
<p><strong><code>prefarea</code> (<span
class="math inline">596, 900 €</span>)</strong> :</p>
<ul>
<li>Vivre dans une zone privilégiée augmente le prix moyen de la maison
de <span class="math inline">596, 900 €</span>. Cela met en évidence
l'importance de l'emplacement dans l'évaluation immobilière.</li>
</ul>
<p><strong><code>furnishing_status_furnished</code> (<span
class="math inline"> − 31.540 €</span>)</strong> :</p>
<ul>
<li>Toute chose étant égale par ailleurs, ce coeeficient négatif montre
que une maison meublée voit son prix diminué de <span
class="math inline">31.540 €</span> par rapport à une maison non meublée
ou semi-meublée. Toutefois, cette variable n'est pas significative
(<span class="math inline"><em>p</em> = 0.764</span>), donc son impact
est négligeable dans ce modèle.</li>
</ul>
<p><strong><code>furnishing_status_semi-furnished</code> (<span
class="math inline">106.600 €</span>)</strong> :</p>
<ul>
<li>Une maison semi-meublée a un prix supérieur de <span
class="math inline">106.600 €</span> par rapport à une maison meublée.
Cependant, cette variable n'est pas significative (<span
class="math inline"><em>p</em> = 0.236</span>), ce qui suggère que son
influence est incertaine.</li>
</ul>
<p><strong><code>furnishing_status_unfurnished</code> (<span
class="math inline"> − 304, 800 €</span>)</strong> :</p>
<ul>
<li>Un statut de maison non meublée réduit significativement son prix en
moyenne de <span class="math inline">304, 800 €</span> par rapport à
d'autres statuts, reflétant l'importance des meubles dans la
valorisation d'une maison.</li>
</ul>
<h3 id="variables-significatives">Variables significatives</h3>
<p>Les <strong>variables significatives</strong> sont identifiées grâce
à la <strong>valeur <span class="math inline"><em>p</em></span> (<span
class="math inline"><em>P</em> &gt; |<em>t</em>|</span>)</strong>. Une
variable est considérée comme statistiquement significative si sa valeur
<span class="math inline"><em>p</em></span> est inférieure à <span
class="math inline">0.05</span>. Voici les variables significatives dans
ce modèle :</p>
<p>Les variables telles que <code>area</code>, <code>bedrooms</code>,
<code>bathrooms</code>, <code>stories</code>, <code>mainroad</code>,
<code>guestroom</code>, <code>basement</code>,
<code>hotwaterheating</code>, <code>air_conditioning</code>,
<code>parking</code>, <code>prefarea</code> et
<code>furnishing_status_unfurnished</code> sont les variables
significatives du modèle car elles ont des <span
class="math inline"><em>p</em></span>-values inférieures à <span
class="math inline">0.05</span>.</p>
<p>Les variables comme <code>furnishing_status_furnished</code> et
<code>furnishing_status_semi-furnished</code> ont des <span
class="math inline"><em>p</em></span>-values élevées (<span
class="math inline"> &gt; 0.05</span>), indiquant qu'elles ne sont pas
significatives pour le modèle.</p>
<h3 id="commentaire-sur-r2">Commentaire sur <span
class="math inline"><em>R</em><sup>2</sup></span></h3>
<p>Le coefficient de détermination <span
class="math inline"><em>R</em><sup>2</sup></span> du modèle est
<strong><span class="math inline">0.702</span></strong>, ce qui signifie
que <span class="math inline">70.2 %</span> de la variance des prix des
maisons est expliquée par les caractéristiques incluses dans le modèle,
contrairement au modèle Baseline qui ne fourni que que <span
class="math inline">21%</span> . C'est un bon indicateur que le modèle
capture une grande partie des variations des prix, mais il reste <span
class="math inline">29.8 %</span> de la variance non expliquée, ce qui
pourrait être attribué à des facteurs non inclus dans les données ou à
des relations non linéaires.</p>
<h3 id="conclusion">Conclusion</h3>
<ol>
<li>Les variables comme la superficie (<code>area</code>), le nombre de
salles de bain (<code>bathrooms</code>), et la présence de climatisation
(<code>air_conditioning</code>) sont les plus influentes et
significatives pour prédire le prix des maisons.</li>
<li>Les variables avec des coefficients non significatifs (comme
<code>furnishing_status_furnished</code>) pourraient être exclues dans
les futurs modèles pour réduire la complexité.</li>
<li>Le <span class="math inline"><em>R</em><sup>2</sup></span> montre
que le modèle est performant, mais il reste des variations inexpliquées,
ce qui pourrait nécessiter des approches plus complexes comme des
modèles non linéaires ou ensemblistes pour améliorer les
prédictions.</li>
</ol>
<p>Passons maintenant à l’évaluation du modèle de régression linéaire en
utilisant nos métriques prédéfinies, à savoir le MAE, le RMSE, et le
<span class="math inline"><em>R</em><sup>2</sup></span>, afin de
quantifier ses performances sur les ensembles d’entraînement et de
test.</p>
</div>
<div class="cell code" data-execution_count="18">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 1 : Initialisation et entraînement du modèle de régression linéaire</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>linear_model <span class="op">=</span> LinearRegression()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>linear_model.fit(data_prix_train, price_train)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 2 : Prédictions sur les ensembles d&#39;entraînement et de test</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>price_train_predicted <span class="op">=</span> linear_model.predict(data_prix_train)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>price_test_predicted <span class="op">=</span> linear_model.predict(data_prix_test)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 3 : Évaluation des performances du modèle sur l&#39;ensemble d&#39;entraînement</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>mae_train <span class="op">=</span> mean_absolute_error(price_train, price_train_predicted)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>rmse_train <span class="op">=</span> np.sqrt(mean_squared_error(price_train, price_train_predicted))</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>r2_train <span class="op">=</span> r2_score(price_train, price_train_predicted)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Performance sur l&#39;ensemble d&#39;entraînement :&quot;</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MAE (Mean Absolute Error) : </span><span class="sc">{</span>mae_train<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE (Root Mean Squared Error) : </span><span class="sc">{</span>rmse_train<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R² (Coefficient de détermination) : </span><span class="sc">{</span>r2_train<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 4 : Évaluation des performances sur l&#39;ensemble de test</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>mae_test <span class="op">=</span> mean_absolute_error(price_test, price_test_predicted)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>rmse_test <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_predicted))</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>r2_test <span class="op">=</span> r2_score(price_test, price_test_predicted)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Performance sur l&#39;ensemble de test :&quot;</span>)</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;MAE (Mean Absolute Error) : </span><span class="sc">{</span>mae_test<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;RMSE (Root Mean Squared Error) : </span><span class="sc">{</span>rmse_test<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;R² (Coefficient de détermination) : </span><span class="sc">{</span>r2_test<span class="sc">:.2f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Performance sur l&#39;ensemble d&#39;entraînement :
MAE (Mean Absolute Error) : 886258.35
RMSE (Root Mean Squared Error) : 1179995.26
R² (Coefficient de détermination) : 0.70

Performance sur l&#39;ensemble de test :
MAE (Mean Absolute Error) : 901765.43
RMSE (Root Mean Squared Error) : 1199669.34
R² (Coefficient de détermination) : 0.73
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Le modèle de régression linéaire présente des performances similaires
sur les ensembles d’entraînement et de test, ce qui est un bon
indicateur de sa capacité de généralisation. Sur l’ensemble
d’entraînement, le <strong>MAE</strong> est de <strong><span
class="math inline">886, 258.35 €</span></strong>, indiquant une erreur
moyenne absolue modérée, tandis que le <strong>RMSE</strong> est
légèrement plus élevé à <strong><span
class="math inline">1, 179, 995.26 €</span></strong>, reflétant l’impact
des grandes erreurs sur les prédictions. Le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> de
<strong><span class="math inline">0.70</span></strong> montre que le
modèle explique <span class="math inline">70 %</span> de la variance des
prix dans les données d’entraînement, ce qui est une performance
acceptable pour un modèle simple comme la régression linéaire.</p>
<p>Sur l’ensemble de test, les résultats sont très similaires, avec un
<strong>MAE</strong> de <strong><span
class="math inline">901, 765.43 €</span></strong>, un
<strong>RMSE</strong> de <strong><span
class="math inline">1, 199, 669.34 €</span></strong>, et un
<strong><span class="math inline"><em>R</em><sup>2</sup></span></strong>
de <strong><span class="math inline">0.73</span></strong>, indiquant que
le modèle est capable de maintenir ses performances sur des données
qu’il n’a jamais vues. Le faible écart entre les métriques des ensembles
d’entraînement et de test suggère que le modèle n’est ni sous-entraîné
ni surentraîné, ce qui est un point positif.</p>
<p><strong>Conclusion</strong></p>
<p>Le modèle de régression linéaire est relativement performant pour
expliquer la variance des prix des maisons et présente une bonne
capacité de généralisation. Cependant, les erreurs (<strong>MAE</strong>
et <strong>RMSE</strong>) restent élevées en valeur absolue, indiquant
qu’il pourrait ne pas capturer toute la complexité des données. Ces
résultats suggèrent qu’il est nécessaire d’explorer des modèles plus
sophistiqués, comme des modèles non linéaires ou ensemblistes, pour
améliorer les prédictions.</p>
<p>Pour compléter l’évaluation du modèle, nous analysons les prédictions
à l’aide de visualisations, notamment la comparaison des distributions
des prix réels et prédits, le scatter plot des valeurs réelles contre
prédictions, ainsi que la distribution des résidus, afin de mieux
comprendre les forces et les limites du modèle.</p>
</div>
<div class="cell code" data-execution_count="19">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison des distributions des valeurs réelles et prédites</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs réelles&#39;</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test_predicted, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs prédites (Régression Linéaire)&#39;</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Prix des maisons&#39;</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Fréquence&#39;</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparaison des distributions des prix (réels vs prédits - Régression Linéaire)&#39;</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot des valeurs réelles vs prédites</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(price_test, price_test_predicted, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&quot;Prédictions Régression Linéaire&quot;</span>)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>plt.plot([price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], [price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], <span class="st">&#39;r--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Ligne idéale (y=x)&quot;</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Prix réels&quot;</span>)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Prix prédits&quot;</span>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Scatter plot : Prix réels vs Prix prédits (Régression Linéaire)&quot;</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution des résidus</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> price_test <span class="op">-</span> price_test_predicted</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>plt.hist(residuals, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">&quot;Résidus&quot;</span>)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;r&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Moyenne des résidus = 0&quot;</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Résidus (Prix réels - Prix prédits)&quot;</span>)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Fréquence&quot;</span>)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Distribution des résidus (Régression Linéaire)&quot;</span>)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/822f8b73c735ec4085c99addc18f5d6524441f14.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/f7380bd6f1c829ac7ddbd6d059d78db56da38c20.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/9328a9b3e6d81fb2de63e0df5f1f363ff7dca12a.png" /></p>
</div>
</div>
<div class="cell markdown">
<h3 id="analyse-des-graphiques">Analyse des graphiques</h3>
<h4 id="1-histogramme-des-distributions-des-prix-réels-et-prédits">1.
<strong>Histogramme des distributions des prix réels et
prédits</strong></h4>
<p>Cet histogramme montre une correspondance relativement bonne entre
les distributions des prix réels et ceux prédits par la régression
linéaire. Les valeurs réelles (en bleu) et les prédictions (en orange)
présentent une similarité dans leurs formes générales, bien que quelques
différences subsistent dans certaines plages de prix, notamment autour
des pics de distribution. Cela suggère que le modèle capture une partie
importante des tendances des données, mais qu'il reste des erreurs non
négligeables dans certaines plages de prix.</p>
<h4 id="2-scatter-plot-prix-réels-vs-prix-prédits">2. <strong>Scatter
plot (Prix réels vs Prix prédits)</strong></h4>
<p>Le scatter plot montre une forte concentration de points autour de la
ligne idéale <span class="math inline"><em>y</em> = <em>x</em></span>,
ce qui indique que les prédictions du modèle sont proches des prix réels
pour une grande partie des données. Cependant, on observe une dispersion
plus marquée pour les prix plus élevés, ce qui indique que le modèle a
plus de difficulté à prédire correctement les valeurs élevées. Cela
pourrait être dû à une sous-représentation de ces cas dans les données
d'entraînement ou à une limitation de la linéarité du modèle.</p>
<h4 id="3-distribution-des-résidus">3. <strong>Distribution des
résidus</strong></h4>
<p>La distribution des résidus (différences entre les prix réels et
prédits) est centrée autour de <span class="math inline">0</span>, ce
qui est un bon signe d'équilibre des prédictions. Cependant, la présence
de résidus plus importants dans les plages positives et négatives
indique que certaines prédictions divergent significativement des
valeurs réelles. Cette distribution symétrique, mais légèrement étalée,
suggère que le modèle fonctionne bien dans la majorité des cas, mais
qu'il est sensible aux écarts extrêmes, probablement liés aux valeurs
aberrantes.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Les visualisations confirment que le modèle de régression linéaire
est capable de capturer les tendances principales des données, avec une
correspondance acceptable entre les prix réels et prédits. Cependant,
les graphiques mettent également en évidence certaines limitations,
notamment dans la prédiction des prix élevés et la présence de résidus
significatifs dans ces cas. Bien que ce modèle offre une base solide,
des approches plus complexes pourraient être nécessaires pour améliorer
la précision globale, notamment dans la gestion des cas extrêmes.</p>
<p>Pour améliorer les performances de la prédiction des prix des
maisons, nous introduisons le modèle de Random Forest, une méthode
ensembliste qui combine plusieurs arbres de décision pour capturer les
relations complexes entre les variables explicatives et la cible, tout
en réduisant le risque de surapprentissage.</p>
<h2 id="e-modèle-ensembliste-random-forest"><span
class="math inline"><em>e</em></span>. Modèle ensembliste (Random
Forest)</h2>
<p>Le modèle Random Forest est une méthode ensembliste puissante qui
repose sur la combinaison de plusieurs arbres de décision pour effectuer
des prédictions plus robustes et précises. Chaque arbre est construit
sur un échantillon aléatoire des données (avec remise), et à chaque
nœud, un sous-ensemble aléatoire des variables explicatives est utilisé
pour déterminer la meilleure division. Cette approche introduit de la
diversité entre les arbres, réduisant ainsi le risque de
surapprentissage. Les prédictions finales sont obtenues en agrégeant les
résultats de tous les arbres, soit par une moyenne (régression) soit par
un vote majoritaire (classification). Le Random Forest est apprécié pour
sa capacité à gérer des données complexes et bruitées, à capturer des
interactions non linéaires, et à fournir une estimation de l’importance
des variables, tout en nécessitant peu de réglages par rapport à
d’autres modèles avancés. Cependant, il peut être coûteux en termes de
calcul, surtout pour des ensembles de données volumineux.</p>
<p>L'algorithme suivant permet de mettre en place ce modèle.</p>
</div>
<div class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 1 : Impact du nombre d’arbres (n_estimators)</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>n_estimators_list <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">500</span>, <span class="dv">1000</span>]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>results_n_estimators <span class="op">=</span> []</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>train_scores_n <span class="op">=</span> []</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>test_scores_n <span class="op">=</span> []</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>train_rmse_n <span class="op">=</span> []</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>test_rmse_n <span class="op">=</span> []</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>train_mae_n <span class="op">=</span> []</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>test_mae_n <span class="op">=</span> []</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> n_estimators_list:</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    rf_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span>n, max_depth<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    rf_model.fit(data_prix_train, price_train)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prédictions</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    price_train_pred <span class="op">=</span> rf_model.predict(data_prix_train)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>    price_test_pred <span class="op">=</span> rf_model.predict(data_prix_test)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcul des métriques</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    mae_train <span class="op">=</span> mean_absolute_error(price_train, price_train_pred)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>    rmse_train <span class="op">=</span> np.sqrt(mean_squared_error(price_train, price_train_pred))</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    r2_train <span class="op">=</span> r2_score(price_train, price_train_pred)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    mae_test <span class="op">=</span> mean_absolute_error(price_test, price_test_pred)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>    rmse_test <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_pred))</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    r2_test <span class="op">=</span> r2_score(price_test, price_test_pred)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    train_scores_n.append(r2_train)</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>    test_scores_n.append(r2_test)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>    train_rmse_n.append(rmse_train)</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>    test_rmse_n.append(rmse_test)</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>    train_mae_n.append(mae_train)</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>    test_mae_n.append(mae_test)</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>    results_n_estimators.append({</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;n_estimators&#39;</span>: n,</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_train&#39;</span>: mae_train,</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_train&#39;</span>: rmse_train,</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_train&#39;</span>: r2_train,</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_test&#39;</span>: mae_test,</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_test&#39;</span>: rmse_test,</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_test&#39;</span>: r2_test</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertion des résultats en DataFrame</span></span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>results_df_n_estimators <span class="op">=</span> pd.DataFrame(results_n_estimators)</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage les résultats</span></span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Performances des modèles en fonction du nombre d’arbres (n_estimators) :&quot;</span>)</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df_n_estimators)</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 2 : Impact de la profondeur maximale des arbres (max_depth)</span></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>max_depth_list <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="va">None</span>]</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>results_max_depth <span class="op">=</span> []</span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>train_scores_d <span class="op">=</span> []</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>test_scores_d <span class="op">=</span> []</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>train_rmse_d <span class="op">=</span> []</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>test_rmse_d <span class="op">=</span> []</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>train_mae_d <span class="op">=</span> []</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>test_mae_d <span class="op">=</span> []</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> max_depth_list:</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>    rf_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span>depth, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>    rf_model.fit(data_prix_train, price_train)</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prédictions</span></span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>    price_train_pred <span class="op">=</span> rf_model.predict(data_prix_train)</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>    price_test_pred <span class="op">=</span> rf_model.predict(data_prix_test)</span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcul des métriques</span></span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a>    mae_train <span class="op">=</span> mean_absolute_error(price_train, price_train_pred)</span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>    rmse_train <span class="op">=</span> np.sqrt(mean_squared_error(price_train, price_train_pred))</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a>    r2_train <span class="op">=</span> r2_score(price_train, price_train_pred)</span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>    mae_test <span class="op">=</span> mean_absolute_error(price_test, price_test_pred)</span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a>    rmse_test <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_pred))</span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a>    r2_test <span class="op">=</span> r2_score(price_test, price_test_pred)</span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a>    train_scores_d.append(r2_train)</span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a>    test_scores_d.append(r2_test)</span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a>    train_rmse_d.append(rmse_train)</span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a>    test_rmse_d.append(rmse_test)</span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a>    train_mae_d.append(mae_train)</span>
<span id="cb32-86"><a href="#cb32-86" aria-hidden="true" tabindex="-1"></a>    test_mae_d.append(mae_test)</span>
<span id="cb32-87"><a href="#cb32-87" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a>    results_max_depth.append({</span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;max_depth&#39;</span>: depth,</span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_train&#39;</span>: mae_train,</span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_train&#39;</span>: rmse_train,</span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_train&#39;</span>: r2_train,</span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_test&#39;</span>: mae_test,</span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_test&#39;</span>: rmse_test,</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_test&#39;</span>: r2_test</span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertion les résultats en DataFrame</span></span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a>results_df_max_depth <span class="op">=</span> pd.DataFrame(results_max_depth)</span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des résultats</span></span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> Performances des modèles en fonction de la profondeur maximale des arbres (max_depth) :&quot;</span>)</span>
<span id="cb32-103"><a href="#cb32-103" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df_max_depth)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Performances des modèles en fonction du nombre d’arbres (n_estimators) :
   n_estimators      MAE_train     RMSE_train  R2_train       MAE_test  \
0            10  372522.413065  531375.934013  0.939472  750439.549188   
1            50  350494.623957  497011.431189  0.947048  729130.957683   
2           100  338743.983533  486015.855147  0.949365  718917.344601   
3           200  336862.027552  482783.660158  0.950036  714212.186444   
4           300  335124.297200  477211.632495  0.951183  713476.288612   
5           500  334231.273081  475965.560184  0.951438  710632.918176   
6          1000  335104.654314  478700.232915  0.950878  709256.288929   

      RMSE_test   R2_test  
0  1.055299e+06  0.789215  
1  1.011001e+06  0.806540  
2  1.004118e+06  0.809165  
3  1.001003e+06  0.810347  
4  9.913788e+05  0.813977  
5  9.892763e+05  0.814765  
6  9.917088e+05  0.813853  

 Performances des modèles en fonction de la profondeur maximale des arbres (max_depth) :
   max_depth     MAE_train    RMSE_train  R2_train      MAE_test  \
0        2.0  1.111435e+06  1.432988e+06  0.559815  1.240652e+06   
1        5.0  7.331432e+05  9.764724e+05  0.795605  9.007263e+05   
2       10.0  3.387440e+05  4.860159e+05  0.949365  7.189173e+05   
3       15.0  2.755026e+05  4.248214e+05  0.961313  7.090370e+05   
4       20.0  2.728510e+05  4.233635e+05  0.961578  7.011220e+05   
5        NaN  2.726488e+05  4.233523e+05  0.961580  7.007916e+05   

      RMSE_test   R2_test  
0  1.590881e+06  0.520969  
1  1.184427e+06  0.734475  
2  1.004118e+06  0.809165  
3  1.007267e+06  0.807966  
4  9.988796e+05  0.811151  
5  9.990770e+05  0.811076  
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="analyse-des-performances-du-modèle-random-forest">Analyse des
performances du modèle Random Forest</h3>
<p>Les résultats montrent que le modèle <strong>Random Forest</strong>
ajuste progressivement ses performances en fonction du <strong>nombre
d’arbres (<code>n_estimators</code>)</strong> et de la
<strong>profondeur maximale des arbres
(<code>max_depth</code>)</strong>. Voici une analyse des deux
paramètres.</p>
<h4 id="1-impact-du-nombre-darbres-n_estimators"><strong>1. Impact du
nombre d’arbres (<code>n_estimators</code>)</strong>:</h4>
<p>Les performances du modèle s’améliorent avec l’augmentation du nombre
d’arbres, jusqu’à atteindre une stabilisation au-delà de <strong><span
class="math inline">300</span> arbres</strong>. Par exemple :</p>
<ul>
<li>Sur l’ensemble d’entraînement, le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> passe de
<strong><span class="math inline">0.94</span></strong> avec 10 arbres à
<strong><span class="math inline">0.95</span></strong> avec <span
class="math inline">500</span> arbres. Les erreurs moyennes se réduisent
également, avec un <strong>MAE</strong> diminuant de <strong><span
class="math inline">372, 522.41 €</span></strong> à <strong><span
class="math inline">334, 231.27 €</span></strong>.</li>
<li>Sur l’ensemble de test, le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> augmente
également, passant de <strong><span
class="math inline">0.79</span></strong> avec <span
class="math inline">10</span> arbres à <strong><span
class="math inline">0.81</span></strong> avec 500 arbres. Le
<strong>MAE</strong> diminue de <strong><span
class="math inline">750, 439.55 €</span></strong> à <strong><span
class="math inline">710, 632.92 €</span></strong>, indiquant une
meilleure précision des prédictions. Cependant, le gain marginal entre
<strong><span class="math inline">300</span></strong> et <strong><span
class="math inline">500</span> arbres</strong> est minime, suggérant que
l’ajout d’arbres au-delà de <strong><span
class="math inline">300</span></strong> n’apporte que peu
d’amélioration.</li>
</ul>
<h4
id="2-impact-de-la-profondeur-maximale-des-arbres-max_depth-"><strong>2.
Impact de la profondeur maximale des arbres
(<code>max_depth</code>)</strong> :</h4>
<p>La profondeur des arbres joue un rôle crucial dans la capacité du
modèle à capturer les relations complexes dans les données :</p>
<ul>
<li>Avec une profondeur faible (<strong>max_depth=2</strong>), le modèle
est sous-ajusté, comme le montre un <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> de
<strong><span class="math inline">0.56</span></strong> sur l’ensemble
d’entraînement et de <strong><span
class="math inline">0.52</span></strong> sur l’ensemble de test. Les
erreurs, comme le <strong>MAE</strong> de <strong><span
class="math inline">1, 111, 435.00 €</span></strong> sur l’ensemble
d’entraînement, sont élevées, indiquant que le modèle est trop
simplifié.</li>
<li>Une profondeur plus élevée améliore considérablement les
performances. À <strong>max_depth=10</strong>, le modèle atteint un
<strong><span class="math inline"><em>R</em><sup>2</sup></span></strong>
de <strong><span class="math inline">0.95</span></strong> sur l’ensemble
d’entraînement et de <strong><span
class="math inline">0.81</span></strong> sur l’ensemble de test, avec un
<strong>MAE</strong> de <strong><span
class="math inline">709, 173.00 €</span></strong> sur le test.</li>
<li>Une profondeur excessive (au-delà de <strong><span
class="math inline">15</span></strong>) offre peu d’amélioration sur
l’ensemble de test, avec un <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> stable autour
de <strong><span class="math inline">0.81</span></strong>. Cependant, le
<strong>MAE</strong> et le <strong>RMSE</strong> de l’ensemble
d’entraînement continuent de diminuer, signalant un possible
surajustement.</li>
</ul>
<h3 id="conclusion">Conclusion</h3>
<p>Le modèle <strong>Random Forest</strong>, contrairement aux modèles
Baseline et Linéaires, montre des performances solides avec une
configuration de <strong><span class="math inline">300</span>
arbres</strong> et une <strong>profondeur maximale de <span
class="math inline">10</span></strong>. Ces paramètres permettent
d’équilibrer le compromis entre précision et généralisation. L’ajout de
plus d’arbres ou l’augmentation excessive de la profondeur apporte des
gains marginaux sur l’ensemble de test, tout en augmentant les risques
de surajustement. Ces résultats confirment la capacité du modèle à
capturer des relations complexes dans les données, tout en maintenant
une bonne capacité de généralisation, ce qui en fait une méthode robuste
pour ce projet contrairement à un modèle plus simple comme la régression
linéaire.</p>
<p>Nous pouvons analyser les perofrmances de ce modèle à travers les
graphiques suivants.</p>
</div>
<div class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison des distributions des valeurs réelles et prédites</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs réelles&#39;</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test_pred, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs prédites (Random Forest)&#39;</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Prix des maisons&#39;</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Fréquence&#39;</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparaison des distributions des prix (réels vs prédits - Random Forest)&#39;</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot des valeurs réelles vs prédites</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(price_test, price_test_pred, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&quot;Prédictions Random Forest&quot;</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>plt.plot([price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], [price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], <span class="st">&#39;r--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Ligne idéale (y=x)&quot;</span>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Prix réels&quot;</span>)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Prix prédits&quot;</span>)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Scatter plot : Prix réels vs Prix prédits (Random Forest)&quot;</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution des résidus</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>residuals_rf <span class="op">=</span> price_test <span class="op">-</span> price_test_pred</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>plt.hist(residuals_rf, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">&quot;Résidus&quot;</span>)</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;r&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Moyenne des résidus = 0&quot;</span>)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Résidus (Prix réels - Prix prédits)&quot;</span>)</span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Fréquence&quot;</span>)</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Distribution des résidus (Random Forest)&quot;</span>)</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation de l&#39;impact du nombre d&#39;arbres</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, train_scores_n, label<span class="op">=</span><span class="st">&quot;R² - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, test_scores_n, label<span class="op">=</span><span class="st">&quot;R² - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Nombre d&#39;arbres (n_estimators)&quot;</span>)</span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;R²&quot;</span>)</span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact du nombre d&#39;arbres sur les performances du Random Forest&quot;</span>)</span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, train_mae_n, label<span class="op">=</span><span class="st">&quot;MAE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, test_mae_n, label<span class="op">=</span><span class="st">&quot;MAE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Nombre d&#39;arbres (n_estimators)&quot;</span>)</span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MAE&quot;</span>)</span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact du nombre d&#39;arbres sur MAE (Random Forest)&quot;</span>)</span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-52"><a href="#cb34-52" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, train_rmse_n, label<span class="op">=</span><span class="st">&quot;RMSE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-53"><a href="#cb34-53" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, test_rmse_n, label<span class="op">=</span><span class="st">&quot;RMSE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-54"><a href="#cb34-54" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Nombre d&#39;arbres (n_estimators)&quot;</span>)</span>
<span id="cb34-55"><a href="#cb34-55" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;RMSE&quot;</span>)</span>
<span id="cb34-56"><a href="#cb34-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact du nombre d&#39;arbres sur RMSE (Random Forest)&quot;</span>)</span>
<span id="cb34-57"><a href="#cb34-57" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-58"><a href="#cb34-58" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-59"><a href="#cb34-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-60"><a href="#cb34-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation de l&#39;impact de la profondeur</span></span>
<span id="cb34-61"><a href="#cb34-61" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-62"><a href="#cb34-62" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">str</span>(d) <span class="cf">for</span> d <span class="kw">in</span> max_depth_list], train_scores_d, label<span class="op">=</span><span class="st">&quot;R² - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-63"><a href="#cb34-63" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">str</span>(d) <span class="cf">for</span> d <span class="kw">in</span> max_depth_list], test_scores_d, label<span class="op">=</span><span class="st">&quot;R² - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-64"><a href="#cb34-64" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Profondeur maximale des arbres (max_depth)&quot;</span>)</span>
<span id="cb34-65"><a href="#cb34-65" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;R²&quot;</span>)</span>
<span id="cb34-66"><a href="#cb34-66" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact de la profondeur maximale sur les performances du Random Forest&quot;</span>)</span>
<span id="cb34-67"><a href="#cb34-67" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-68"><a href="#cb34-68" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-69"><a href="#cb34-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-70"><a href="#cb34-70" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-71"><a href="#cb34-71" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">str</span>(d) <span class="cf">for</span> d <span class="kw">in</span> max_depth_list], train_mae_d, label<span class="op">=</span><span class="st">&quot;MAE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-72"><a href="#cb34-72" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">str</span>(d) <span class="cf">for</span> d <span class="kw">in</span> max_depth_list], test_mae_d, label<span class="op">=</span><span class="st">&quot;MAE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-73"><a href="#cb34-73" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Profondeur maximale des arbres (max_depth)&quot;</span>)</span>
<span id="cb34-74"><a href="#cb34-74" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MAE&quot;</span>)</span>
<span id="cb34-75"><a href="#cb34-75" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact de la profondeur maximale sur MAE (Random Forest)&quot;</span>)</span>
<span id="cb34-76"><a href="#cb34-76" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-77"><a href="#cb34-77" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb34-78"><a href="#cb34-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-79"><a href="#cb34-79" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb34-80"><a href="#cb34-80" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">str</span>(d) <span class="cf">for</span> d <span class="kw">in</span> max_depth_list], train_rmse_d, label<span class="op">=</span><span class="st">&quot;RMSE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-81"><a href="#cb34-81" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="bu">str</span>(d) <span class="cf">for</span> d <span class="kw">in</span> max_depth_list], test_rmse_d, label<span class="op">=</span><span class="st">&quot;RMSE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb34-82"><a href="#cb34-82" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Profondeur maximale des arbres (max_depth)&quot;</span>)</span>
<span id="cb34-83"><a href="#cb34-83" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;RMSE&quot;</span>)</span>
<span id="cb34-84"><a href="#cb34-84" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact de la profondeur maximale sur RMSE (Random Forest)&quot;</span>)</span>
<span id="cb34-85"><a href="#cb34-85" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb34-86"><a href="#cb34-86" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/406ed511fda3651f1e4672da52f412f456dabe9e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/9b5e3cdb32896bd1974c93fbdc8e18f7a5ce05e0.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/33015f3c4e72fcb26591cbdf633c6480917c3cd3.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/ebee53d1215d00cacd4521f9d04ce3d38401f7c9.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/d214a3e20babab26813d95f8b68256059111112a.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/8c0bc712a9b7097ac1a69e9d0816d15d81e73082.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/70e1532495e30d448d77e3e81c1cbcdc67b186c6.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/a45149cb430d2498212cc971052954cb2405fdec.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/9e35b166bab27f4045cf413365c6f84addf1549b.png" /></p>
</div>
</div>
<div class="cell markdown">
<h3 id="commentaires-des-graphiques">Commentaires des graphiques</h3>
<ol>
<li><p><strong>Comparaison des distributions des prix (réels vs prédits
- Random Forest)</strong></p>
<p>Ce graphique montre que la distribution des prix prédites par le
modèle Random Forest suit globalement celle des prix réels, mais il
existe quelques écarts. La courbe des prédictions semble légèrement
moins étendue que celle des prix réels, indiquant que le modèle tend à
lisser certaines variations. Ces écarts pourraient refléter des
limitations du modèle dans la capture de certains comportements
extrêmes.</p></li>
<li><p><strong>Scatter plot : Prix réels vs Prix prédits (Random
Forest)</strong></p>
<p>Le nuage de points est bien aligné avec la ligne idéale <span
class="math inline"><em>y</em> = <em>x</em></span>, ce qui démontre une
bonne capacité du modèle à prédire les prix. Toutefois, quelques écarts
importants sont visibles, surtout pour les valeurs les plus élevées,
indiquant des prédictions moins précises pour les maisons les plus
chères. Globalement, le modèle Random Forest est performant, avec une
grande majorité des prédictions proches des valeurs réelles.</p></li>
<li><p><strong>Distribution des résidus (Random Forest)</strong></p>
<p>La distribution des résidus est centrée autour de zéro, ce qui est un
bon signe d'un modèle bien ajusté. Toutefois, des queues légèrement plus
épaisses montrent que certaines prédictions présentent des erreurs
significatives, notamment dans les deux extrémités. Une distribution
symétrique indique que le modèle ne montre pas de biais systématique
dans ses prédictions.</p></li>
<li><p><strong>Impact du nombre d'arbres sur les performances du Random
Forest</strong></p>
<p>L'analyse des graphes montre que l'augmentation du nombre d'arbres
améliore les performances sur les ensembles d'entraînement et de test,
mais les gains deviennent marginaux au-delà de <strong><span
class="math inline">300</span> arbres</strong>, ce qui suggère que
l'ajout d'arbres supplémentaires n'apporte pas de valeur significative
:</p>
<ul>
<li>Sur <strong>l'ensemble d'entraînement</strong>, le
<strong>MAE</strong> diminue pour se stabiliser autour de <strong><span
class="math inline">335, 000€</span></strong>, tandis que le
<strong>RMSE</strong> atteint environ <strong><span
class="math inline">475, 000€</span></strong>. Cela montre une meilleure
précision des prédictions à mesure que le modèle devient plus
robuste.</li>
<li>Sur <strong>l'ensemble de test</strong>, le <strong>MAE</strong> et
le <strong>RMSE</strong> diminuent également avec l'augmentation du
nombre d'arbres, mais les gains deviennent minimes au-delà de 300
arbres. Le <strong>MAE</strong> reste légèrement supérieur à
<strong><span class="math inline">700, 000€</span></strong>, et le
<strong>RMSE</strong> est stable autour de <strong><span
class="math inline">990, 000€</span></strong>, indiquant une bonne
généralisation avec un compromis entre complexité et précision.</li>
<li>En termes de <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong>, les
performances se stabilisent à environ <strong><span
class="math inline">0.96</span></strong> pour l'entraînement et
<strong><span class="math inline">0.81</span></strong> pour le test. Ce
comportement indique que l'ajout d'arbres supplémentaires au-delà de 300
n'améliore pas significativement les performances globales.</li>
</ul></li>
<li><p><strong>Impact de la profondeur maximale des arbres sur les
performances du Random Forest</strong></p>
<p>L'augmentation de la profondeur maximale des arbres montre une
tendance au surapprentissage à des valeurs plus élevées :</p>
<ul>
<li>Sur <strong>l'ensemble d'entraînement</strong>, le
<strong>MAE</strong> et le <strong>RMSE</strong> diminuent fortement à
mesure que la profondeur augmente, atteignant environ <strong><span
class="math inline">275, 000€</span></strong> pour le
<strong>MAE</strong> et <strong><span
class="math inline">420, 000€</span></strong> pour le
<strong>RMSE</strong> lorsque la profondeur est fixée à 15 ou plus. Cela
reflète une capture accrue des relations dans les données
d'entraînement.</li>
<li>Sur <strong>l'ensemble de test</strong>, les performances se
stabilisent pour des profondeurs supérieures à <strong><span
class="math inline">10</span></strong>, avec un <strong>MAE</strong>
d'environ <strong><span class="math inline">710, 000€</span></strong> et
un <strong>RMSE</strong> autour de <strong><span
class="math inline">1, 000, 000€</span></strong>. Ces résultats
suggèrent que des profondeurs plus élevées n'améliorent pas les
performances sur des données non vues.</li>
<li>Le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> pour
l'entraînement atteint près de <strong><span
class="math inline">0.96</span></strong>, tandis que sur le test, il
reste stable à <strong><span class="math inline">0.81</span></strong>
au-delà d'une profondeur de 10, renforçant l'idée qu'une profondeur
excessive mène à un surajustement.</li>
</ul></li>
</ol>
<h3 id="conclusion">Conclusion</h3>
<p>Pour le modèle Random Forest, les paramètres optimaux semblent être
<strong><span class="math inline">300</span> arbres</strong> et une
<strong>profondeur maximale de <span
class="math inline">10</span></strong>, offrant un équilibre entre
précision et généralisation. L'augmentation des hyperparamètres au-delà
de ces valeurs n'apporte que des améliorations négligeables, tout en
augmentant les risques de surapprentissage et le temps de calcul. Ces
observations confirment la robustesse et la flexibilité de Random Forest
pour ce type de problème de régression complexe.</p>
<h2 id="f-modèle-ensembliste-gradient-boosting"><span
class="math inline"><em>f</em></span>. Modèle ensembliste (Gradient
Boosting)</h2>
<p>Le <strong>Gradient Boosting</strong> est un modèle ensembliste qui
construit une série d'arbres de décision faibles, généralement peu
profonds, en les combinant de manière séquentielle pour améliorer les
prédictions. Contrairement à la méthode Random Forest qui crée des
arbres indépendants, le Gradient Boosting ajuste chaque arbre pour
corriger les erreurs des arbres précédents. Ce processus repose sur
l'optimisation d'une fonction de perte (comme l'erreur quadratique
moyenne pour la régression), où chaque nouvel arbre est formé pour
minimiser cette perte sur les résidus. L'algorithme attribue des poids
plus élevés aux observations mal prédites, ce qui lui permet de se
concentrer sur les erreurs les plus importantes. Bien qu'il offre une
grande flexibilité et des performances élevées, le Gradient Boosting
peut être sensible au surapprentissage, mais cela peut être contrôlé
grâce à des hyperparamètres tels que
<strong><code>n_estimators</code></strong> (nombre d'arbres),
<strong><code>learning_rate</code></strong> (taux d'apprentissage), et
<strong><code>max_depth</code></strong> (profondeur des arbres). Ce
modèle est largement utilisé pour les tâches de régression et de
classification grâce à son équilibre entre précision et
interprétabilité.</p>
<p>L'algorithme suivant permet de mettre en place ce modèle.</p>
</div>
<div class="cell code" data-execution_count="22">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 1 : Impact du nombre d&#39;arbres (n_estimators)</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>n_estimators_list <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">500</span>, <span class="dv">1000</span>]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>results_n_estimators <span class="op">=</span> []</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> n_estimators_list:</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialisation du modèle avec une profondeur fixe</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    gb_model <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span>n, max_depth<span class="op">=</span><span class="dv">3</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    gb_model.fit(data_prix_train, price_train)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prédictions</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    price_train_pred <span class="op">=</span> gb_model.predict(data_prix_train)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    price_test_pred <span class="op">=</span> gb_model.predict(data_prix_test)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcul des métriques</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    mae_train <span class="op">=</span> mean_absolute_error(price_train, price_train_pred)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    rmse_train <span class="op">=</span> np.sqrt(mean_squared_error(price_train, price_train_pred))</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    r2_train <span class="op">=</span> r2_score(price_train, price_train_pred)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    mae_test <span class="op">=</span> mean_absolute_error(price_test, price_test_pred)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    rmse_test <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_pred))</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    r2_test <span class="op">=</span> r2_score(price_test, price_test_pred)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Enregistrement des résultats</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    results_n_estimators.append({</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;n_estimators&#39;</span>: n,</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_train&#39;</span>: mae_train,</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_train&#39;</span>: rmse_train,</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_train&#39;</span>: r2_train,</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_test&#39;</span>: mae_test,</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_test&#39;</span>: rmse_test,</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_test&#39;</span>: r2_test</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertion des résultats en DataFrame</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>results_df_n_estimators <span class="op">=</span> pd.DataFrame(results_n_estimators)</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des résultats</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Résultats en fonction du nombre d&#39;arbres (n_estimators) :&quot;</span>)</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df_n_estimators)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 2 : Impact de la profondeur maximale des arbres (max_depth)</span></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>max_depth_list <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="va">None</span>]</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>results_max_depth <span class="op">=</span> []</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> max_depth_list:</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialisation le modèle avec un nombre d&#39;arbres fixe</span></span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a>    gb_model <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span>depth, learning_rate<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>    gb_model.fit(data_prix_train, price_train)</span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prédictions</span></span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a>    price_train_pred <span class="op">=</span> gb_model.predict(data_prix_train)</span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a>    price_test_pred <span class="op">=</span> gb_model.predict(data_prix_test)</span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcul des métriques</span></span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a>    mae_train <span class="op">=</span> mean_absolute_error(price_train, price_train_pred)</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a>    rmse_train <span class="op">=</span> np.sqrt(mean_squared_error(price_train, price_train_pred))</span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a>    r2_train <span class="op">=</span> r2_score(price_train, price_train_pred)</span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a>    mae_test <span class="op">=</span> mean_absolute_error(price_test, price_test_pred)</span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a>    rmse_test <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_pred))</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a>    r2_test <span class="op">=</span> r2_score(price_test, price_test_pred)</span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Enregistrement des résultats</span></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a>    results_max_depth.append({</span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;max_depth&#39;</span>: depth,</span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_train&#39;</span>: mae_train,</span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_train&#39;</span>: rmse_train,</span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_train&#39;</span>: r2_train,</span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_test&#39;</span>: mae_test,</span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_test&#39;</span>: rmse_test,</span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_test&#39;</span>: r2_test</span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-74"><a href="#cb35-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertion des résultats en DataFrame</span></span>
<span id="cb35-75"><a href="#cb35-75" aria-hidden="true" tabindex="-1"></a>results_df_max_depth <span class="op">=</span> pd.DataFrame(results_max_depth)</span>
<span id="cb35-76"><a href="#cb35-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-77"><a href="#cb35-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage les résultats</span></span>
<span id="cb35-78"><a href="#cb35-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Résultats en fonction de la profondeur maximale des arbres (max_depth) :&quot;</span>)</span>
<span id="cb35-79"><a href="#cb35-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df_max_depth)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Résultats en fonction du nombre d&#39;arbres (n_estimators) :
   n_estimators     MAE_train    RMSE_train  R2_train      MAE_test  \
0            10  1.131274e+06  1.406440e+06  0.575974  1.234479e+06   
1            50  6.984965e+05  9.212736e+05  0.818061  8.062376e+05   
2           100  6.003094e+05  7.959148e+05  0.864205  7.373581e+05   
3           200  4.943381e+05  6.559758e+05  0.907759  7.186480e+05   
4           300  4.300068e+05  5.790954e+05  0.928113  7.301346e+05   
5           500  3.392868e+05  4.721814e+05  0.952207  7.607541e+05   
6          1000  2.308326e+05  3.646794e+05  0.971492  7.854549e+05   

      RMSE_test   R2_test  
0  1.546353e+06  0.547409  
1  1.083638e+06  0.777742  
2  1.023251e+06  0.801823  
3  1.000902e+06  0.810386  
4  1.018912e+06  0.803500  
5  1.071355e+06  0.782752  
6  1.134345e+06  0.756455  
Résultats en fonction de la profondeur maximale des arbres (max_depth) :
   max_depth      MAE_train     RMSE_train  R2_train       MAE_test  \
0        2.0  736973.409451  980881.089672  0.793756  832480.712247   
1        5.0  310506.122631  445429.141218  0.957469  681867.115748   
2       10.0   34157.078994  214736.209018  0.990115  666880.233550   
3       15.0   28143.356627  214491.360720  0.990138  688409.439325   
4       20.0   28140.842550  214491.359122  0.990138  693845.800798   
5        NaN   28140.842550  214491.359122  0.990138  694480.194657   

      RMSE_test   R2_test  
0  1.126974e+06  0.759610  
1  9.870517e+05  0.815597  
2  1.114974e+06  0.764702  
3  1.184855e+06  0.734283  
4  1.199702e+06  0.727582  
5  1.199370e+06  0.727733  
</code></pre>
</div>
</div>
<div class="cell markdown">
<h3 id="analyse-des-performances-du-modèle-gradient-boosting">Analyse
des performances du modèle Gradient Boosting</h3>
<p>Les résultats obtenus pour le modèle <strong>Gradient
Boosting</strong> mettent en évidence l'impact significatif des
hyperparamètres <strong>n_estimators</strong> (nombre d'arbres) et
<strong>max_depth</strong> (profondeur maximale des arbres) sur les
performances du modèle. Voici une analyse détaillée de ces deux
paramètres :</p>
<h4 id="1-impact-du-nombre-darbres-n_estimators-"><strong>1. Impact du
nombre d’arbres (n_estimators) :</strong></h4>
<p>L'augmentation du nombre d'arbres améliore les performances du
modèle, tant sur l'ensemble d'entraînement que sur l'ensemble de test,
jusqu'à un certain point où les gains deviennent marginaux, voire se
dégradent :</p>
<ul>
<li>Sur l'ensemble <strong>d’entraînement</strong>, le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> passe de
<strong><span class="math inline">0.58</span></strong> avec 10 arbres à
<strong><span class="math inline">0.97</span></strong> avec <span
class="math inline">1000</span> arbres, montrant que le modèle devient
de plus en plus performant pour ajuster les données. Les erreurs
moyennes diminuent significativement, avec un <strong>MAE</strong>
passant de <strong><span
class="math inline">1, 131, 274.00€</span></strong> à <strong><span
class="math inline">230, 832.60€</span></strong>, et un
<strong>RMSE</strong> passant de <strong><span
class="math inline">1, 406, 440.00€</span></strong> à <strong><span
class="math inline">364, 679.40€</span></strong>.</li>
<li>Sur l'ensemble <strong>de test</strong>, les performances augmentent
initialement, avec un <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> passant de
<strong><span class="math inline">0.55</span></strong> avec 10 arbres à
un pic de <strong><span class="math inline">0.81</span></strong> avec
200 arbres. Les erreurs, mesurées par le <strong>MAE</strong> et le
<strong>RMSE</strong>, diminuent initialement (<strong>MAE</strong>
passant de <strong><span
class="math inline">1, 234, 479.00€</span></strong> à <strong><span
class="math inline">718, 648.00€</span></strong>, <strong>RMSE</strong>
passant de <strong><span
class="math inline">1, 546, 353.00€</span></strong> à <strong><span
class="math inline">1, 000, 902.00€</span></strong>). Cependant, au-delà
de 300 arbres, le modèle commence à montrer des signes de surajustement,
avec des performances légèrement dégradées sur l'ensemble de test
(<strong><span
class="math inline"><em>R</em><sup>2</sup> = 0.75</span></strong>,
<strong>MAE=<span class="math inline">785, 454.90€</span></strong>,
<strong>RMSE=<span class="math inline">1, 134, 345.00€</span></strong>
avec 1000 arbres).</li>
</ul>
<p>Ces observations soulignent qu'un nombre optimal d'arbres se situe
autour de <strong><span class="math inline">200 − 300</span></strong>
pour maintenir un bon équilibre entre ajustement et généralisation.</p>
<h4
id="2-impact-de-la-profondeur-maximale-des-arbres-max_depth-"><strong>2.
Impact de la profondeur maximale des arbres (max_depth) :</strong></h4>
<p>La profondeur maximale des arbres joue un rôle crucial dans la
capacité du modèle à capturer des relations complexes dans les données.
Cependant, des profondeurs excessives entraînent un surajustement :</p>
<ul>
<li>Avec une profondeur faible (<strong>max_depth=2</strong>), le modèle
est sous-ajusté, avec un <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> de
<strong><span class="math inline">0.79</span></strong> sur
l'entraînement et de <strong><span
class="math inline">0.76</span></strong> sur le test. Les erreurs
restent élevées, avec un <strong>MAE</strong> de <strong><span
class="math inline">736, 973.40€</span></strong> sur l'entraînement et
<strong>832,480.71€</strong> sur le test.</li>
<li>Une profondeur moyenne (<strong>max_depth=5</strong>) offre un bon
compromis, avec un <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> de
<strong><span class="math inline">0.96</span></strong> sur
l'entraînement et de <strong><span
class="math inline">0.81</span></strong> sur le test. Les erreurs sont
significativement réduites (<strong>MAE=<span
class="math inline">310, 506.12€</span></strong> sur l'entraînement et
<strong><span class="math inline">681, 867.12€</span></strong> sur le
test, <strong>RMSE=<span
class="math inline">445, 429.14€</span></strong> sur l'entraînement et
<strong><span class="math inline">987, 051.70€</span></strong> sur le
test).</li>
<li>Avec des profondeurs élevées (<strong>max_depth=10 ou
plus</strong>), le modèle montre des signes de surajustement. Par
exemple, le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> sur
l'entraînement atteint <strong><span
class="math inline">0.99</span></strong>, mais il diminue légèrement sur
le test (<strong><span
class="math inline"><em>R</em><sup>2</sup> = 0.76</span></strong>). Les
erreurs sur le test augmentent également, avec un <strong>MAE=<span
class="math inline">666, 880.23€</span></strong> et un
<strong>RMSE=<span class="math inline">1, 114, 974.00€</span></strong>
pour <strong>max_depth=10</strong>.</li>
</ul>
<p>Ces résultats indiquent qu'une profondeur modérée
(<strong>max_depth=5</strong>) est optimale pour ce modèle, permettant
un bon compromis entre la précision sur l'entraînement et la
généralisation sur le test.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Le modèle <strong>Gradient Boosting</strong> montre des performances
solides et une capacité à généraliser sur des données non vues lorsque
les hyperparamètres sont bien calibrés contrairement aux modèles
précédents :</p>
<ul>
<li><strong>Nombre optimal d'arbres</strong> : Environ <strong><span
class="math inline">200 − 300</span></strong>, où le modèle atteint un
bon compromis entre généralisation et précision, avec un <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> stable autour
de <strong><span class="math inline">0.81</span></strong> sur le
test.</li>
<li><strong>Profondeur optimale des arbres</strong> :
<strong>max_depth=5</strong>, permettant au modèle de capturer les
relations complexes dans les données sans tomber dans le
surajustement.</li>
</ul>
<p>Toutefois, au-delà de ces valeurs, le modèle commence à surapprendre
les données d'entraînement, ce qui se traduit par une dégradation des
performances sur l'ensemble de test. Cela met en évidence l'importance
de calibrer soigneusement les hyperparamètres pour maintenir un bon
équilibre entre ajustement et généralisation.</p>
<p>Nous pouvons également visualiser les performances de ce modèle à
travers les graphiques suivants.</p>
</div>
<div class="cell code" data-execution_count="23">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison des distributions des valeurs réelles et prédites</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs réelles&#39;</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>plt.hist(price_test_pred, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&#39;Valeurs prédites (Gradient Boosting)&#39;</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Prix des maisons&#39;</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Fréquence&#39;</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Comparaison des distributions des prix (réels vs prédits - Gradient Boosting)&#39;</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot des valeurs réelles vs prédites</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>plt.scatter(price_test, price_test_pred, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">&quot;Prédictions Gradient Boosting&quot;</span>)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>plt.plot([price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], [price_test.<span class="bu">min</span>(), price_test.<span class="bu">max</span>()], <span class="st">&#39;r--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Ligne idéale (y=x)&quot;</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Prix réels&quot;</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Prix prédits&quot;</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Scatter plot : Prix réels vs Prix prédits (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution des résidus</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>residuals_gb <span class="op">=</span> price_test <span class="op">-</span> price_test_pred</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>plt.hist(residuals_gb, bins<span class="op">=</span><span class="dv">20</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">&quot;Résidus&quot;</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>plt.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;r&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&quot;Moyenne des résidus = 0&quot;</span>)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Résidus (Prix réels - Prix prédits)&quot;</span>)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Fréquence&quot;</span>)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Distribution des résidus (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation de l&#39;impact du nombre d&#39;arbres</span></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, results_df_n_estimators[<span class="st">&#39;R2_train&#39;</span>], label<span class="op">=</span><span class="st">&quot;R² - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, results_df_n_estimators[<span class="st">&#39;R2_test&#39;</span>], label<span class="op">=</span><span class="st">&quot;R² - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Nombre d&#39;arbres (n_estimators)&quot;</span>)</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;R²&quot;</span>)</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact du nombre d&#39;arbres sur les performances (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, results_df_n_estimators[<span class="st">&#39;MAE_train&#39;</span>], label<span class="op">=</span><span class="st">&quot;MAE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, results_df_n_estimators[<span class="st">&#39;MAE_test&#39;</span>], label<span class="op">=</span><span class="st">&quot;MAE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Nombre d&#39;arbres (n_estimators)&quot;</span>)</span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MAE&quot;</span>)</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact du nombre d&#39;arbres sur les performances (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, results_df_n_estimators[<span class="st">&#39;RMSE_train&#39;</span>], label<span class="op">=</span><span class="st">&quot;RMSE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a>plt.plot(n_estimators_list, results_df_n_estimators[<span class="st">&#39;RMSE_test&#39;</span>], label<span class="op">=</span><span class="st">&quot;RMSE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Nombre d&#39;arbres (n_estimators)&quot;</span>)</span>
<span id="cb37-54"><a href="#cb37-54" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;RMSE&quot;</span>)</span>
<span id="cb37-55"><a href="#cb37-55" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact du nombre d&#39;arbres sur les performances (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-56"><a href="#cb37-56" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-57"><a href="#cb37-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-58"><a href="#cb37-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-59"><a href="#cb37-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Étape 2 : Impact de la profondeur maximale des arbres (max_depth)</span></span>
<span id="cb37-60"><a href="#cb37-60" aria-hidden="true" tabindex="-1"></a>max_depth_list <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>]</span>
<span id="cb37-61"><a href="#cb37-61" aria-hidden="true" tabindex="-1"></a>results_max_depth <span class="op">=</span> []</span>
<span id="cb37-62"><a href="#cb37-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-63"><a href="#cb37-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> max_depth_list:</span>
<span id="cb37-64"><a href="#cb37-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialisation du modèle avec un nombre d’arbres fixe</span></span>
<span id="cb37-65"><a href="#cb37-65" aria-hidden="true" tabindex="-1"></a>    gb_model <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span>depth, learning_rate<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb37-66"><a href="#cb37-66" aria-hidden="true" tabindex="-1"></a>    gb_model.fit(data_prix_train, price_train)</span>
<span id="cb37-67"><a href="#cb37-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-68"><a href="#cb37-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prédictions</span></span>
<span id="cb37-69"><a href="#cb37-69" aria-hidden="true" tabindex="-1"></a>    price_train_pred <span class="op">=</span> gb_model.predict(data_prix_train)</span>
<span id="cb37-70"><a href="#cb37-70" aria-hidden="true" tabindex="-1"></a>    price_test_pred <span class="op">=</span> gb_model.predict(data_prix_test)</span>
<span id="cb37-71"><a href="#cb37-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-72"><a href="#cb37-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcul des métriques</span></span>
<span id="cb37-73"><a href="#cb37-73" aria-hidden="true" tabindex="-1"></a>    mae_train <span class="op">=</span> mean_absolute_error(price_train, price_train_pred)</span>
<span id="cb37-74"><a href="#cb37-74" aria-hidden="true" tabindex="-1"></a>    rmse_train <span class="op">=</span> np.sqrt(mean_squared_error(price_train, price_train_pred))</span>
<span id="cb37-75"><a href="#cb37-75" aria-hidden="true" tabindex="-1"></a>    r2_train <span class="op">=</span> r2_score(price_train, price_train_pred)</span>
<span id="cb37-76"><a href="#cb37-76" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-77"><a href="#cb37-77" aria-hidden="true" tabindex="-1"></a>    mae_test <span class="op">=</span> mean_absolute_error(price_test, price_test_pred)</span>
<span id="cb37-78"><a href="#cb37-78" aria-hidden="true" tabindex="-1"></a>    rmse_test <span class="op">=</span> np.sqrt(mean_squared_error(price_test, price_test_pred))</span>
<span id="cb37-79"><a href="#cb37-79" aria-hidden="true" tabindex="-1"></a>    r2_test <span class="op">=</span> r2_score(price_test, price_test_pred)</span>
<span id="cb37-80"><a href="#cb37-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-81"><a href="#cb37-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Enregistrement des résultats</span></span>
<span id="cb37-82"><a href="#cb37-82" aria-hidden="true" tabindex="-1"></a>    results_max_depth.append({</span>
<span id="cb37-83"><a href="#cb37-83" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;max_depth&#39;</span>: depth,</span>
<span id="cb37-84"><a href="#cb37-84" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_train&#39;</span>: mae_train,</span>
<span id="cb37-85"><a href="#cb37-85" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_train&#39;</span>: rmse_train,</span>
<span id="cb37-86"><a href="#cb37-86" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_train&#39;</span>: r2_train,</span>
<span id="cb37-87"><a href="#cb37-87" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;MAE_test&#39;</span>: mae_test,</span>
<span id="cb37-88"><a href="#cb37-88" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;RMSE_test&#39;</span>: rmse_test,</span>
<span id="cb37-89"><a href="#cb37-89" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;R2_test&#39;</span>: r2_test</span>
<span id="cb37-90"><a href="#cb37-90" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb37-91"><a href="#cb37-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-92"><a href="#cb37-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Convertion des résultats en DataFrame</span></span>
<span id="cb37-93"><a href="#cb37-93" aria-hidden="true" tabindex="-1"></a>results_df_max_depth <span class="op">=</span> pd.DataFrame(results_max_depth)</span>
<span id="cb37-94"><a href="#cb37-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-95"><a href="#cb37-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation de l&#39;impact de la profondeur maximale</span></span>
<span id="cb37-96"><a href="#cb37-96" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-97"><a href="#cb37-97" aria-hidden="true" tabindex="-1"></a>plt.plot(max_depth_list, results_df_max_depth[<span class="st">&#39;R2_train&#39;</span>], label<span class="op">=</span><span class="st">&quot;R² - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-98"><a href="#cb37-98" aria-hidden="true" tabindex="-1"></a>plt.plot(max_depth_list, results_df_max_depth[<span class="st">&#39;R2_test&#39;</span>], label<span class="op">=</span><span class="st">&quot;R² - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-99"><a href="#cb37-99" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Profondeur maximale des arbres (max_depth)&quot;</span>)</span>
<span id="cb37-100"><a href="#cb37-100" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;R²&quot;</span>)</span>
<span id="cb37-101"><a href="#cb37-101" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact de la profondeur maximale des arbres (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-102"><a href="#cb37-102" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-103"><a href="#cb37-103" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-104"><a href="#cb37-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-105"><a href="#cb37-105" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-106"><a href="#cb37-106" aria-hidden="true" tabindex="-1"></a>plt.plot(max_depth_list, results_df_max_depth[<span class="st">&#39;MAE_train&#39;</span>], label<span class="op">=</span><span class="st">&quot;MAE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-107"><a href="#cb37-107" aria-hidden="true" tabindex="-1"></a>plt.plot(max_depth_list, results_df_max_depth[<span class="st">&#39;MAE_test&#39;</span>], label<span class="op">=</span><span class="st">&quot;MAE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-108"><a href="#cb37-108" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Profondeur maximale des arbres (max_depth)&quot;</span>)</span>
<span id="cb37-109"><a href="#cb37-109" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MAE&quot;</span>)</span>
<span id="cb37-110"><a href="#cb37-110" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact de la profondeur maximale des arbres (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-111"><a href="#cb37-111" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-112"><a href="#cb37-112" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb37-113"><a href="#cb37-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-114"><a href="#cb37-114" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb37-115"><a href="#cb37-115" aria-hidden="true" tabindex="-1"></a>plt.plot(max_depth_list, results_df_max_depth[<span class="st">&#39;RMSE_train&#39;</span>], label<span class="op">=</span><span class="st">&quot;RMSE - Train&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-116"><a href="#cb37-116" aria-hidden="true" tabindex="-1"></a>plt.plot(max_depth_list, results_df_max_depth[<span class="st">&#39;RMSE_test&#39;</span>], label<span class="op">=</span><span class="st">&quot;RMSE - Test&quot;</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>)</span>
<span id="cb37-117"><a href="#cb37-117" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Profondeur maximale des arbres (max_depth)&quot;</span>)</span>
<span id="cb37-118"><a href="#cb37-118" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;RMSE&quot;</span>)</span>
<span id="cb37-119"><a href="#cb37-119" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Impact de la profondeur maximale des arbres (Gradient Boosting)&quot;</span>)</span>
<span id="cb37-120"><a href="#cb37-120" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb37-121"><a href="#cb37-121" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/3837d5f2ac16e8356e948fa18db113f8d62e2d04.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/c407dbb22023f554d089236989570cd248384e43.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/29aff46c12254a8230c62a431ab1dc35bce77fb1.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/810c9438a47476873785a947fccf6e80eb8f2f2e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/69cec1c09bd1aad5f594e21f8e9a9e60db800935.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/560de7bb77c04c52cbe347db48aa252763fa712e.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/b3ced787d6a4007bf03d72d4a7c5b5c596947166.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/c4107d26db97023833be435bfa2447d88dfb2ab9.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/f9672f8dd6dee3d2e1d333737a870569ce9afa39.png" /></p>
</div>
</div>
<div class="cell markdown">
<h3 id="commentaires-des-graphiques">Commentaires des graphiques</h3>
<ol>
<li><p><strong>Comparaison des distributions des prix (réels vs prédits
- Gradient Boosting)</strong><br />
Le graphique montre que la distribution des prix prédits par le modèle
Gradient Boosting suit bien celle des prix réels. Cependant, on observe
quelques écarts, notamment dans les queues de distribution, où le modèle
semble avoir des difficultés à capturer certaines valeurs extrêmes.
Globalement, le modèle parvient à reproduire les tendances principales,
mais une légère amélioration pourrait être apportée pour mieux capturer
les prix les plus élevés et les plus bas.</p></li>
<li><p><strong>Scatter plot : Prix réels vs Prix prédits (Gradient
Boosting)</strong><br />
Ce graphique illustre la corrélation entre les prix réels et prédits. La
majorité des points se situe près de la ligne idéale <span
class="math inline"><em>y</em> = <em>x</em></span>, indiquant une bonne
précision du modèle. Toutefois, quelques points éloignés,
particulièrement pour les valeurs les plus élevées, signalent des
prédictions moins précises dans ces cas. Ces écarts pourraient refléter
des variations complexes ou des limites dans la capacité du modèle à
généraliser pour ces observations.</p></li>
<li><p><strong>Distribution des résidus (Gradient
Boosting)</strong><br />
La distribution des résidus est centrée autour de zéro, suggérant un
modèle équilibré sans biais systématique. Cependant, des résidus
légèrement plus importants aux extrémités montrent que certaines
prédictions comportent des erreurs plus significatives. Une distribution
symétrique, comme celle observée ici, est un indicateur positif pour un
modèle de régression.</p></li>
<li><p><strong>Impact du nombre d'arbres sur les performances du
Gradient Boosting</strong><br />
Les graphiques montrent que l'augmentation du nombre d'arbres améliore
les performances, mais seulement jusqu'à un certain seuil :</p></li>
</ol>
<ul>
<li>Sur <strong>l'ensemble d'entraînement</strong>, le
<strong>MAE</strong> et le <strong>RMSE</strong> diminuent constamment
avec l'ajout d'arbres, atteignant respectivement environ <strong><span
class="math inline">230, 000€</span></strong> et <strong><span
class="math inline">360, 000€</span></strong> avec 1000 arbres. Le
<strong><span class="math inline"><em>R</em><sup>2</sup></span></strong>
progresse également pour atteindre près de <strong><span
class="math inline">0.97</span></strong>, indiquant une excellente
adéquation aux données d'entraînement.</li>
<li>Sur <strong>l'ensemble de test</strong>, les métriques (MAE et RMSE)
diminuent jusqu'à environ <span class="math inline">200</span> arbres,
où elles atteignent un minimum de <strong><span
class="math inline">720, 000€</span></strong> et <strong><span
class="math inline">1, 000, 000€</span></strong> respectivement, avant
de remonter légèrement avec un grand nombre d'arbres. Cela peut indiquer
un début de surapprentissage. Le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> pour le test
suit une tendance similaire, atteignant un maximum de <strong><span
class="math inline">0.81</span></strong> pour environ <span
class="math inline">200</span> arbres avant de diminuer légèrement.</li>
</ul>
<ol>
<li><strong>Impact de la profondeur maximale des arbres sur les
performances du Gradient Boosting</strong><br />
L'augmentation de la profondeur des arbres a un impact notable sur les
performances, mais des profondeurs trop importantes peuvent entraîner un
surapprentissage :</li>
</ol>
<ul>
<li>Sur <strong>l'ensemble d'entraînement</strong>, le
<strong>MAE</strong> et le <strong>RMSE</strong> diminuent fortement
avec une profondeur croissante, atteignant environ <strong><span
class="math inline">28, 000€</span></strong> pour le
<strong>MAE</strong> et <strong><span
class="math inline">210, 000€</span></strong> pour le
<strong>RMSE</strong> à des profondeurs élevées (10 ou plus). Cela
montre une forte capacité du modèle à s'adapter aux données
d'entraînement.</li>
<li>Sur <strong>l'ensemble de test</strong>, les performances sont
meilleures avec une profondeur modérée (entre 5 et 7), où le
<strong>MAE</strong> et le <strong>RMSE</strong> atteignent
respectivement environ <strong><span
class="math inline">680, 000€</span></strong> et <strong><span
class="math inline">980, 000€</span></strong>. Une profondeur excessive
(10 ou plus) entraîne une dégradation des performances, avec une
augmentation du <strong>RMSE</strong> au-delà de <strong><span
class="math inline">1, 100, 000€</span></strong>. Le <strong><span
class="math inline"><em>R</em><sup>2</sup></span></strong> reste stable
autour de <strong><span class="math inline">0.81</span></strong> pour
des profondeurs entre <span class="math inline">5</span> et <span
class="math inline">7</span>, mais diminue pour des profondeurs plus
importantes.</li>
</ul>
<h3 id="conclusion">Conclusion</h3>
<p>Le modèle Gradient Boosting montre des performances solides et la
capacité de capturer les tendances des prix des maisons. Cependant, il
est essentiel de trouver un équilibre dans le choix des hyperparamètres
pour éviter le surajustement. Une configuration de <span
class="math inline">300</span> arbres et une profondeur maximale entre
<span class="math inline">5</span> et <span class="math inline">7</span>
semble offrir le meilleur compromis entre précision et généralisation,
comme le montrent les métriques (<span
class="math inline"><em>R</em><sup>2</sup></span>, MAE, RMSE) sur les
ensembles d'entraînement et de test.</p>
</div>
<section id="g-importance-des-features-pour-un-modèle-ensembliste"
class="cell markdown">
<h2><span class="math inline"><em>g</em></span>. Importance des Features
pour un Modèle Ensembliste</h2>
<ol>
<li><strong>Extraction des “Features Importances”</strong></li>
</ol>
<p>Les modèles ensemblistes comme Random Forest et Gradient Boosting
incluent des fonctionnalités intégrées dans Scikit-learn pour mesurer
l’importance des variables explicatives. Cette importance est calculée
automatiquement au cours de l’entraînement du modèle et est accessible
via l’attribut feature_importances_. Cet attribut retourne un score pour
chaque feature, représentant son rôle relatif dans les prédictions
globales du modèle.</p>
<ol>
<li><strong>Méthodes d'interprétation des Résultats</strong></li>
</ol>
<ul>
<li><strong>Features importantes</strong> : Les features ayant une
importance élevée contribuent fortement à la prédiction du prix des
maisons. Ces variables sont essentielles pour le modèle et devraient
être conservées pour maintenir de bonnes performances.</li>
<li><strong>Features moins importantes</strong> : Les features avec une
importance faible ou nulle peuvent être considérées comme peu
pertinentes ou redondantes. Leur suppression peut améliorer l’efficacité
du modèle sans affecter ses performances, tout en réduisant le bruit et
le risque de surapprentissage.</li>
</ul>
<ol>
<li><strong>Calcul de l’Importance des Features</strong></li>
</ol>
<p>L’importance des features dans les modèles ensemblistes est calculée
à l’aide de la <strong>réduction moyenne de l’impureté</strong>
(<em>Mean Decrease in Impurity</em> - MDI). Chaque fois qu’une feature
est utilisée pour effectuer une division dans un arbre de décision, elle
réduit l’impureté des sous-ensembles créés (par exemple, la réduction de
l’entropie ou de l’indice de Gini). Les contributions de cette réduction
pour chaque feature sont additionnées sur tous les arbres et normalisées
pour obtenir un score.</p>
<p><strong>Formellement</strong> :</p>
<ul>
<li>La réduction de l’impureté pour une feature <span
class="math inline"><em>f</em><sub><em>i</em></sub></span> est calculée
comme :</li>
</ul>
<p><span class="math display">$$
\text{Importance}(f_i) = \frac{1}{T} \sum_{t=1}^{T} \sum_{s \in
\text{splits}(t, f_i)} \Delta \text{Impureté}(s)
$$</span></p>
<p>où :</p>
<ul>
<li><span class="math inline"><em>T</em></span> est le nombre total
d’arbres.</li>
<li><span class="math inline"><em>Δ</em>Impureté(<em>s</em>)</span>
représente la réduction de l’impureté pour un split <span
class="math inline"><em>s</em></span> impliquant la feature <span
class="math inline"><em>f</em><sub><em>i</em></sub></span>.</li>
</ul>
<p>Dans un modèle <strong>Random Forest</strong>, ces scores sont
moyennés sur tous les arbres.<br />
Dans un modèle <strong>Gradient Boosting</strong>, la même logique est
utilisée, mais les scores sont pondérés par l’importance de chaque arbre
dans le processus de boosting.</p>
<h3 id="a-importance-des-features-pour-le-modèle-random-forest"><span
class="math inline"><em>a</em></span>. Importance des Features pour le
Modèle Random Forest</h3>
<p>Pour le modèle Random Forest de <span class="math inline">300</span>
arbres avec <span class="math inline">10</span> profondeurs, nous avons
mis en place le code suivant pour trouver les features clés pour
optimiser les performances et réduire la complexité.</p>
</section>
<div class="cell code" data-execution_count="24">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Entraînement du modèle Random Forest</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>random_forest_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">300</span>, max_depth<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>random_forest_model.fit(data_prix_train, price_train)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extraction des importances des features</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> random_forest_model.feature_importances_</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> data_prix_train.columns</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Création d&#39;un DataFrame pour organiser les résultats</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;Feature&#39;</span>: features, <span class="st">&#39;Importance&#39;</span>: feature_importances})</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> importance_df.sort_values(by<span class="op">=</span><span class="st">&#39;Importance&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des importances des features</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>plt.barh(importance_df[<span class="st">&#39;Feature&#39;</span>], importance_df[<span class="st">&#39;Importance&#39;</span>], color<span class="op">=</span><span class="st">&#39;skyblue&#39;</span>)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Importance des Features&quot;</span>)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Features&quot;</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Importance des Features selon Random Forest&quot;</span>)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()  <span class="co"># Inverser l&#39;ordre des features pour une meilleure lisibilité</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des résultats sous forme de tableau</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/0678e3357bf9aad3b05fc68e3cebf5c3a144c826.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>                             Feature  Importance
0                               area    0.407431
2                          bathrooms    0.268716
9                            parking    0.055335
3                            stories    0.048622
8                   air_conditioning    0.037482
7                    hotwaterheating    0.029921
13     furnishing_status_unfurnished    0.028110
1                           bedrooms    0.026771
10                          prefarea    0.025609
6                           basement    0.022000
5                          guestroom    0.017345
11       furnishing_status_furnished    0.013665
12  furnishing_status_semi-furnished    0.012710
4                           mainroad    0.006283
</code></pre>
</div>
</div>
<div class="cell markdown">
<h4 id="analyse-des-importances-des-features---random-forest">Analyse
des Importances des Features - Random Forest</h4>
<p>L’analyse des importances des features révèle que
<strong><code>area</code></strong> (superficie) est la variable la plus
influente dans la prédiction du prix des maisons, avec une contribution
de <strong><span class="math inline">40.74%</span></strong>, suivie par
<strong><code>bathrooms</code></strong> (<strong><span
class="math inline">26.87%</span></strong>), ce qui souligne leur rôle
crucial dans la détermination du prix. Des variables comme
<strong><code>parking</code></strong> (<strong><span
class="math inline">5.53%</span></strong>) et
<strong><code>stories</code></strong> (<strong><span
class="math inline">4.86%</span></strong>) jouent également un rôle
important, bien qu’avec une influence moindre. Les fonctionnalités liées
à l’équipement et au confort, telles que
<strong><code>air_conditioning</code></strong> (<strong><span
class="math inline">3.75%</span></strong>) et
<strong><code>hotwaterheating</code></strong> (<strong><span
class="math inline">3%</span></strong>), montrent une contribution
significative mais moins centrale.</p>
<p>En revanche, des variables comme
<strong><code>mainroad</code></strong> (<strong><span
class="math inline">0.06%</span></strong>) et
<strong><code>furnishing_status_furnished</code></strong> (<strong><span
class="math inline">1.37%</span></strong>) ont une importance
négligeable, suggérant qu’elles contribuent peu à la prédiction globale
et pourraient être candidates à une élimination dans un processus de
simplification du modèle.</p>
<h4 id="conclusion">Conclusion</h4>
<p>Ces résultats confirment que les caractéristiques liées à la
superficie, au nombre de salles de bain et aux commodités principales
sont essentielles pour expliquer les variations des prix. À l’inverse,
les variables avec des importances faibles ou nulles, telles que
<strong><code>mainroad</code></strong>, pourraient être supprimées pour
améliorer l’efficacité et la simplicité du modèle sans nuire à ses
performances.</p>
<h3
id="b-importance-des-features-pour-le-modèle-gradient-boosting"><span
class="math inline"><em>b</em></span>. Importance des Features pour le
Modèle Gradient Boosting</h3>
<p>Pour le modèle Gradient Boosting avec <span
class="math inline">300</span> itérations et une profondeur maximale de
<span class="math inline">6</span>, nous avons mis en place le code
suivant pour identifier les features clés afin d’optimiser les
performances et réduire la complexité.</p>
</div>
<div class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Entraînement du modèle Gradient Boosting</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>gradient_boosting_model <span class="op">=</span> GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">300</span>, max_depth<span class="op">=</span><span class="dv">6</span>, random_state<span class="op">=</span><span class="dv">42</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>gradient_boosting_model.fit(data_prix_train, price_train)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extraction des importances des features</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>feature_importances_gb <span class="op">=</span> gradient_boosting_model.feature_importances_</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> data_prix_train.columns</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Création d&#39;un DataFrame pour organiser les résultats</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>importance_df_gb <span class="op">=</span> pd.DataFrame({<span class="st">&#39;Feature&#39;</span>: features, <span class="st">&#39;Importance&#39;</span>: feature_importances_gb})</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>importance_df_gb <span class="op">=</span> importance_df_gb.sort_values(by<span class="op">=</span><span class="st">&#39;Importance&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des importances des features</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>plt.barh(importance_df_gb[<span class="st">&#39;Feature&#39;</span>], importance_df_gb[<span class="st">&#39;Importance&#39;</span>], color<span class="op">=</span><span class="st">&#39;salmon&#39;</span>)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Importance des Features&quot;</span>)</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;Features&quot;</span>)</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Importance des Features selon Gradient Boosting&quot;</span>)</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()  <span class="co"># Inverser l&#39;ordre des features pour une meilleure lisibilité</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des résultats sous forme de tableau</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(importance_df_gb)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/410ed5a0d6ad784d8d25f512eaf57e388e384372.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>                             Feature  Importance
0                               area    0.397286
2                          bathrooms    0.284809
9                            parking    0.054499
8                   air_conditioning    0.043056
3                            stories    0.041321
7                    hotwaterheating    0.031287
13     furnishing_status_unfurnished    0.028950
10                          prefarea    0.023740
5                          guestroom    0.023711
1                           bedrooms    0.023130
6                           basement    0.019422
11       furnishing_status_furnished    0.011295
12  furnishing_status_semi-furnished    0.010833
4                           mainroad    0.006661
</code></pre>
</div>
</div>
<div class="cell markdown">
<h4
id="analyse-des-importances-des-features---gradient-boosting">Analyse
des Importances des Features - Gradient Boosting</h4>
<p>L’analyse des importances des features selon le modèle Gradient
Boosting révèle des résultats cohérents et pertinents pour expliquer la
prédiction des prix des maisons. La variable
<strong><code>area</code></strong> est clairement la plus influente,
avec une importance de <strong><span
class="math inline">39.7%</span></strong>, ce qui confirme que la
superficie de la maison est un facteur déterminant pour estimer son prix
comme nous l'avions constaté lors de l'étude bivariée. La deuxième
variable la plus contributive est
<strong><code>bathrooms</code></strong>, avec une importance de
<strong><span class="math inline">28.5%</span></strong>, soulignant
l’impact significatif du nombre de salles de bain sur la valeur d’une
maison. Ces deux variables dominent largement le modèle, représentant
ensemble environ <strong><span class="math inline">68%</span></strong>
de l’importance totale.</p>
<p>Les autres variables comme <strong><code>parking</code></strong>,
<strong><code>air_conditioning</code></strong>, et
<strong><code>stories</code></strong> ont une contribution modérée, ce
qui suggère qu’elles jouent également un rôle non négligeable dans les
prédictions. En revanche, certaines variables comme
<strong><code>mainroad</code></strong> (<strong><span
class="math inline">0.67%</span></strong>) et les différents états de
mobilier (<strong><code>furnishing_status_furnished</code></strong> et
<strong><code>furnishing_status_semi-furnished</code></strong>) ont une
très faible importance, indiquant qu’elles sont moins pertinentes pour
ce modèle. Cela peut être dû à une faible variation dans ces variables
ou à un impact négligeable sur la valeur finale.</p>
<h4 id="conclusion">Conclusion</h4>
<p>Pour optimiser le modèle, les variables comme
<strong><code>mainroad</code></strong>,
<strong><code>furnishing_status_furnished</code></strong>, et
<strong><code>furnishing_status_semi-furnished</code></strong>
pourraient être envisagées pour suppression ou révision, car elles
apportent peu à la précision du modèle. En revanche, des efforts doivent
être concentrés sur les variables clés telles que
<strong><code>area</code></strong> et
<strong><code>bathrooms</code></strong>, qui sont les moteurs principaux
de la prédiction et justifient leur rôle essentiel dans le modèle. Cela
permettra de réduire le bruit, améliorer l’interprétabilité et
potentiellement renforcer la robustesse du modèle.</p>
<h2
id="h-fine-tuning-des-modèles-ensemblistes--randomizedsearchcv-et-gridsearchcv"><span
class="math inline"><em>h</em></span>. Fine-tuning des Modèles
Ensemblistes : RandomizedSearchCV et GridSearchCV</h2>
<p>La performance des modèles ensemblistes comme <strong>Random
Forest</strong> et <strong>Gradient Boosting</strong> dépend fortement
du choix des hyperparamètres. Les méthodes
<strong>RandomizedSearchCV</strong> et <strong>GridSearchCV</strong>
fournies par la bibliothèque Scikit-learn permettent d’optimiser ces
hyperparamètres en testant différentes combinaisons et en identifiant
celle qui maximise les performances du modèle.</p>
<h3 id="a-différences-entre-randomizedsearchcv-et-gridsearchcv"><span
class="math inline"><em>a</em></span>. Différences entre
RandomizedSearchCV et GridSearchCV</h3>
<h4 id="1-gridsearchcv">1. GridSearchCV</h4>
<ul>
<li><strong>Principe</strong> : GridSearchCV effectue une recherche
exhaustive en testant toutes les combinaisons possibles
d’hyperparamètres spécifiés.</li>
<li><strong>Avantages</strong> : Permet d’explorer systématiquement tout
l’espace des hyperparamètres.</li>
<li><strong>Inconvénients</strong> : Très coûteux en termes de temps de
calcul, surtout lorsque le nombre de combinaisons est élevé.</li>
</ul>
<h4 id="2-randomizedsearchcv">2. RandomizedSearchCV</h4>
<ul>
<li><strong>Principe</strong> : RandomizedSearchCV sélectionne un nombre
fixe de combinaisons aléatoires à partir de l’espace des hyperparamètres
spécifié.</li>
<li><strong>Avantages</strong> : Moins coûteux en temps de calcul.
Permet d’explorer un espace plus large si le nombre d’itérations est
bien défini.</li>
<li><strong>Inconvénients</strong> : Risque de passer à côté de la
meilleure combinaison si le nombre d’itérations est trop faible.</li>
</ul>
<p>En résumé, <strong>GridSearchCV</strong> est préférable lorsque
l’espace des hyperparamètres est petit et que le temps de calcul n’est
pas un facteur limitant, tandis que <strong>RandomizedSearchCV</strong>
est plus adapté lorsque l’espace des hyperparamètres est vaste ou que
les ressources sont limitées.</p>
<h3 id="b-fine-tuning-pour-le-modèle-random-forest"><span
class="math inline"><em>b</em></span>. Fine-tuning pour le Modèle Random
Forest</h3>
<p>Pour <strong>Random Forest</strong>, les hyperparamètres importants à
optimiser sont :</p>
<ul>
<li><strong>n_estimators</strong> : Nombre d’arbres dans la forêt.</li>
<li><strong>max_depth</strong> : Profondeur maximale des arbres.</li>
<li><strong>min_samples_split</strong> : Nombre minimal d’échantillons
requis pour diviser un nœud.</li>
<li><strong>min_samples_leaf</strong> : Nombre minimal d’échantillons
dans une feuille terminale.</li>
</ul>
<h4 id="mise-en-œuvre-de-randomizedsearchcv"><strong>Mise en Œuvre de
RandomizedSearchCV</strong></h4>
</div>
<div class="cell code" data-execution_count="26">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Définition  de l’espace des hyperparamètres</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>param_distributions <span class="op">=</span> {</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">500</span>, <span class="dv">1000</span>],</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">50</span>],</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_split&#39;</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>]</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialisation du modèle</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration du RandomizedSearchCV</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>random_search_rf <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>rf_model,</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    param_distributions<span class="op">=</span>param_distributions,</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    n_iter<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Nombre d’itérations</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>,</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,  <span class="co"># Validation croisée</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Exécution de la recherche</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>random_search_rf.fit(data_prix_train, price_train)</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a><span class="co"># affichages des meilleurs hyperparamètres</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Meilleurs hyperparamètres (RandomizedSearchCV - Random Forest) :&quot;</span>, random_search_rf.best_params_)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Fitting 3 folds for each of 50 candidates, totalling 150 fits
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   1.1s
[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   1.1s
[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   1.1s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=   1.6s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=   1.6s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.6s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=   1.6s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.6s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.2s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.2s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.2s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.6s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.2s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.6s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   0.6s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.4s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.4s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.4s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.1s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   0.7s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.1s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.7s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.6s
[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.2s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   1.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   1.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=   1.4s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time=   1.5s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time=   1.5s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time=   1.5s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   1.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   1.6s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=   1.5s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.8s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.8s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   0.8s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.0s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   0.9s
[CV] END max_depth=15, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   0.9s

Meilleurs hyperparamètres (RandomizedSearchCV - Random Forest) : {&#39;n_estimators&#39;: 1000, &#39;min_samples_split&#39;: 2, &#39;min_samples_leaf&#39;: 1, &#39;max_depth&#39;: 50}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Analyse des Résultats de RandomizedSearchCV pour Random
Forest</strong></p>
<p>Les résultats de la recherche RandomizedSearchCV pour le modèle
<strong>Random Forest</strong> indiquent que les meilleurs
hyperparamètres sont :</p>
<ul>
<li><strong>n_estimators = 1000</strong> : le modèle utilise un nombre
élevé d’arbres pour maximiser la robustesse des prédictions.</li>
<li><strong>min_samples_split = 2</strong> : le critère minimal pour
diviser un nœud est fixé à la valeur minimale, favorisant une
granularité fine.</li>
<li><strong>min_samples_leaf = 1</strong> : chaque feuille terminale
contient au moins un échantillon, permettant une segmentation fine des
données.</li>
<li><strong>max_depth = 50</strong> : une profondeur maximale importante
est choisie, offrant une capacité élevée pour capturer des relations
complexes.</li>
</ul>
<p>Ces choix d’hyperparamètres permettent d’optimiser les performances
sur les données d’entraînement en augmentant la complexité et la
flexibilité du modèle. Cependant, l’utilisation d’un grand nombre
d’arbres (<strong>n_estimators = <span
class="math inline">1000</span></strong>) et d’une profondeur maximale
importante (<strong>max_depth = 50</strong>) pourrait accroître le
risque de surajustement et allonger considérablement le temps
d’entraînement. De plus, les valeurs minimales pour
<strong>min_samples_split</strong> et <strong>min_samples_leaf</strong>
indiquent que le modèle favorise une forte granularité dans la division
des données, ce qui peut être utile pour des structures de données
complexes.</p>
<p>En conclusion, bien que ces hyperparamètres maximisent les
performances sur les données d’entraînement, il est essentiel de
vérifier les performances sur l’ensemble de test pour garantir une bonne
généralisation et éviter un surajustement excessif.</p>
<h4 id="mise-en-œuvre-de-gridsearchcv"><strong>Mise en Œuvre de
GridSearchCV</strong></h4>
</div>
<div class="cell code" data-execution_count="27">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Définition d&#39;une grille restreinte pour les hyperparamètres</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">500</span>],</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>,<span class="dv">50</span>],</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_split&#39;</span>: [<span class="dv">2</span>, <span class="dv">5</span>],</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;min_samples_leaf&#39;</span>: [<span class="dv">1</span>, <span class="dv">2</span>]</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration GridSearchCV</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>grid_search_rf <span class="op">=</span> GridSearchCV(</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>rf_model,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    param_grid<span class="op">=</span>param_grid,</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>,</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Exécution de la recherche</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>grid_search_rf.fit(data_prix_train, price_train)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Meilleurs hyperparamètres</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Meilleurs hyperparamètres (GridSearchCV - Random Forest) :&quot;</span>, grid_search_rf.best_params_)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Fitting 3 folds for each of 48 candidates, totalling 144 fits
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.0s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.0s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.7s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.1s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.9s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.0s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.3s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.8s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.7s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.5s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.4s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.6s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.6s
[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   0.5s

Meilleurs hyperparamètres (GridSearchCV - Random Forest) : {&#39;max_depth&#39;: 10, &#39;min_samples_leaf&#39;: 1, &#39;min_samples_split&#39;: 2, &#39;n_estimators&#39;: 300}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Analyse des Résultats de GridSearchCV pour Random
Forest</strong></p>
<p>Les résultats de la recherche exhaustive GridSearchCV pour le modèle
<strong>Random Forest</strong> indiquent que les meilleurs
hyperparamètres sont :</p>
<ul>
<li><strong>max_depth = 10</strong> : une profondeur modérée est
choisie, favorisant un bon équilibre entre complexité et
généralisation.</li>
<li><strong>min_samples_leaf = 1</strong> : chaque feuille terminale
contient au moins un échantillon, permettant une segmentation fine.</li>
<li><strong>min_samples_split = 2</strong> : le critère minimal pour
diviser un nœud est fixé à la valeur minimale, permettant des arbres
plus détaillés.</li>
<li><strong>n_estimators = 300</strong> : un nombre optimal d’arbres est
utilisé, assurant des performances sans surcharger le calcul.</li>
</ul>
<p>Ces hyperparamètres optimaux permettent au modèle de capturer les
relations essentielles dans les données tout en limitant le risque de
surajustement grâce à une profondeur maximale contrôlée
(<strong>max_depth = 10</strong>) et un nombre raisonnable d’arbres
(<strong>n_estimators = 300</strong>). Contrairement à
RandomizedSearchCV, GridSearchCV explore systématiquement toutes les
combinaisons, ce qui permet de s'assurer que la meilleure configuration
possible a été identifiée. Cependant, cela peut être coûteux en termes
de temps de calcul, comme en témoigne le total de <strong>144
fits</strong> nécessaires dans cet exemple.</p>
<p>En conclusion, la configuration optimale identifiée par GridSearchCV
montre un modèle bien équilibré, apte à généraliser sur des données non
vues, tout en conservant une complexité modérée pour limiter les risques
de surapprentissage.</p>
<h3 id="c-fine-tuning-pour-le-modèle-gradient-boosting"><span
class="math inline"><em>c</em></span>. Fine-tuning pour le Modèle
Gradient Boosting</h3>
<p>Pour <strong>Gradient Boosting</strong>, les hyperparamètres
importants à optimiser sont :</p>
<ul>
<li><strong>n_estimators</strong> : Nombre d’étapes de boosting.</li>
<li><strong>max_depth</strong> : Profondeur maximale des arbres.</li>
<li><strong>learning_rate</strong> : Taux d’apprentissage (impact de
chaque arbre sur le modèle final).</li>
<li><strong>subsample</strong> : Proportion des échantillons utilisés
pour former chaque arbre.</li>
</ul>
<h4 id="mise-en-œuvre-de-randomizedsearchcv"><strong>Mise en Œuvre de
RandomizedSearchCV</strong></h4>
</div>
<div class="cell code" data-execution_count="28">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Définition de l’espace des hyperparamètres</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>param_distributions <span class="op">=</span> {</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">500</span>],</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;learning_rate&#39;</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>],</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;subsample&#39;</span>: [<span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">1.0</span>]</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialisation du modèle</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>gb_model <span class="op">=</span> GradientBoostingRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration RandomizedSearchCV</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>random_search_gb <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>gb_model,</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    param_distributions<span class="op">=</span>param_distributions,</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    n_iter<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>,</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Exécution de la recherche</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>random_search_gb.fit(data_prix_train, price_train)</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des meilleurs hyperparamètres</span></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Meilleurs hyperparamètres (RandomizedSearchCV - Gradient Boosting) :&quot;</span>, random_search_gb.best_params_)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Fitting 3 folds for each of 50 candidates, totalling 150 fits
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   0.7s
[CV] END learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   0.7s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=10, n_estimators=500, subsample=0.6; total time=   0.7s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   0.8s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   0.8s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   0.6s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   0.5s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=1.0; total time=   0.9s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.6; total time=   0.6s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.5s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.5s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.4s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.5s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   0.6s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   0.6s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.6; total time=   0.6s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.5s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.05, max_depth=10, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.05, max_depth=10, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.05, max_depth=10, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   0.5s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   0.5s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   0.7s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   0.7s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=500, subsample=0.8; total time=   0.7s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8; total time=   0.6s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   0.6s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   0.6s
[CV] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   0.6s
[CV] END learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.2, max_depth=10, n_estimators=100, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END learning_rate=0.01, max_depth=10, n_estimators=300, subsample=0.6; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.2s[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.2s

[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.6; total time=   0.2s

Meilleurs hyperparamètres (RandomizedSearchCV - Gradient Boosting) : {&#39;subsample&#39;: 0.6, &#39;n_estimators&#39;: 100, &#39;max_depth&#39;: 5, &#39;learning_rate&#39;: 0.05}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Analyse des Résultats de RandomizedSearchCV pour Gradient
Boosting</strong></p>
<p>Les résultats de <strong>RandomizedSearchCV</strong> pour le modèle
<strong>Gradient Boosting</strong> montrent que les meilleurs
hyperparamètres sont :</p>
<ul>
<li><strong>subsample = 0.6</strong> : seulement 60 % des échantillons
sont utilisés pour entraîner chaque arbre, ce qui aide à réduire le
surapprentissage.</li>
<li><strong>n_estimators = 100</strong> : un nombre modéré d'arbres est
suffisant pour obtenir des performances optimales.</li>
<li><strong>max_depth = 5</strong> : une profondeur d'arbre modérée
permet de capturer des relations complexes tout en limitant la
complexité du modèle.</li>
<li><strong>learning_rate = 0.05</strong> : un taux d’apprentissage
relativement faible assure une convergence stable et robuste.</li>
</ul>
<p>Ces paramètres indiquent que le modèle Gradient Boosting est bien
ajusté pour les données avec une approche prudente, limitant les risques
de surajustement grâce à un sous-échantillonnage contrôlé
(<strong>subsample = 0.6</strong>) et un taux d’apprentissage faible
(<strong>learning_rate = 0.05</strong>). En comparaison avec
GridSearchCV, RandomizedSearchCV explore aléatoirement un sous-ensemble
d’hyperparamètres, ce qui est plus rapide tout en conservant une bonne
chance d’identifier des paramètres performants.</p>
<p>La combinaison optimale d’hyperparamètres identifiée ici montre une
orientation vers une régularisation contrôlée et une complexité modérée,
idéale pour garantir un bon compromis entre performance et
généralisation.</p>
<h4 id="mise-en-œuvre-de-gridsearchcv"><strong>Mise en Œuvre de
GridSearchCV</strong></h4>
</div>
<div class="cell code" data-execution_count="29">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Définition d&#39;une grille restreinte pour les hyperparamètres</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_estimators&#39;</span>: [<span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_depth&#39;</span>: [<span class="dv">5</span>, <span class="dv">7</span>],</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;learning_rate&#39;</span>: [<span class="fl">0.05</span>, <span class="fl">0.1</span>],</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;subsample&#39;</span>: [<span class="fl">0.8</span>, <span class="fl">1.0</span>]</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration GridSearchCV</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>grid_search_gb <span class="op">=</span> GridSearchCV(</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>gb_model,</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    param_grid<span class="op">=</span>param_grid,</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>,</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Exécution de la recherche</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a>grid_search_gb.fit(data_prix_train, price_train)</span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Affichage des meilleurs hyperparamètres</span></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Meilleurs hyperparamètres (GridSearchCV - Gradient Boosting) :&quot;</span>, grid_search_gb.best_params_)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Fitting 3 folds for each of 16 candidates, totalling 48 fits
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.4s
[CV] END learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.4s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.3s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.2s
[CV] END learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=   0.2s

Meilleurs hyperparamètres (GridSearchCV - Gradient Boosting) : {&#39;learning_rate&#39;: 0.05, &#39;max_depth&#39;: 5, &#39;n_estimators&#39;: 200, &#39;subsample&#39;: 0.8}
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>Analyse des Résultats de GridSearchCV pour Gradient
Boosting</strong></p>
<p>Les résultats de <strong>GridSearchCV</strong> pour le modèle
<strong>Gradient Boosting</strong> montrent que les meilleurs
hyperparamètres sont :</p>
<ul>
<li><strong>learning_rate = 0.05</strong> : un taux d’apprentissage
faible qui assure une convergence plus stable et réduit le risque de
surajustement.</li>
<li><strong>max_depth = 5</strong> : une profondeur d’arbre modérée qui
équilibre la capacité du modèle à capturer les relations complexes tout
en limitant la complexité et le surajustement.</li>
<li><strong>n_estimators = 200</strong> : un nombre d’arbres suffisant
pour garantir des performances optimales sans surcharger le modèle.</li>
<li><strong>subsample = 0.8</strong> : 80 % des échantillons sont
utilisés pour entraîner chaque arbre, ce qui ajoute une régularisation
supplémentaire en limitant les corrélations entre les arbres.</li>
</ul>
<p>Ces hyperparamètres montrent une orientation vers un modèle bien
régularisé, capable de généraliser efficacement sur de nouvelles
données. Comparé à RandomizedSearchCV, <strong>GridSearchCV explore de
manière exhaustive toutes les combinaisons possibles</strong>, assurant
ainsi une optimisation plus complète, mais au prix d’un temps de calcul
plus élevé. Les hyperparamètres optimaux trouvés ici sont similaires à
ceux obtenus par RandomizedSearchCV, ce qui renforce la fiabilité de
cette configuration pour ce dataset.</p>
<p>La combinaison optimale identifiée ici met en évidence l’importance
de trouver un compromis entre une complexité suffisante pour capturer
des relations pertinentes et une régularisation pour éviter le
surajustement.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Les fonctions <code>RandomizedSearchCV</code> et
<code>GridSearchCV</code> sont toutes deux des méthodes d’optimisation
des hyperparamètres fournies par Scikit-learn, mais elles diffèrent par
leur approche. <code>GridSearchCV</code> effectue une recherche
exhaustive sur toutes les combinaisons possibles d’hyperparamètres dans
un espace défini. Cela garantit que chaque combinaison est testée, ce
qui permet de trouver l’ensemble optimal avec certitude, à condition que
l’espace soit bien défini. Cependant, cette méthode est coûteuse en
temps et en ressources, surtout lorsque le nombre de combinaisons est
élevé ou lorsque le modèle est complexe. À l’inverse,
<code>RandomizedSearchCV</code> échantillonne aléatoirement un nombre
défini de combinaisons d’hyperparamètres. Cela permet d’explorer
rapidement un espace de recherche potentiellement plus large tout en
réduisant considérablement les coûts de calcul, mais au risque de passer
à côté de l’ensemble optimal si le nombre d’itérations est
insuffisant.</p>
<p>En analysant les résultats, les deux méthodes ont montré des
performances similaires dans l’identification des hyperparamètres
optimaux pour les modèles Random Forest et Gradient Boosting. Cependant,
<code>RandomizedSearchCV</code> s’est révélé plus rapide pour les tests,
tout en obtenant des configurations compétitives (par exemple,
profondeur modérée des arbres et taux d’apprentissage réduit pour
Gradient Boosting). En revanche, <code>GridSearchCV</code>, bien que
plus lent, a confirmé l’efficacité des hyperparamètres identifiés par
<code>RandomizedSearchCV</code> en explorant toutes les combinaisons.
Ainsi, pour des problèmes complexes avec un large espace
d’hyperparamètres, <code>RandomizedSearchCV</code> est préférable pour
une optimisation rapide. En revanche, pour un espace restreint ou des
contraintes moins strictes sur le temps de calcul,
<code>GridSearchCV</code> reste une solution plus exhaustive et
fiable.</p>
<h2
id="i-analyse-de-limpact-de-la-taille-des-données-dentraînement"><span
class="math inline"><em>i</em></span>. Analyse de l’impact de la taille
des données d’entraînement</h2>
<p>Dans un projet de prédiction, la taille des données d’entraînement
joue un rôle crucial dans les performances des modèles. Une base
d’apprentissage trop petite peut limiter la capacité du modèle à
généraliser sur de nouvelles données, tandis qu’une base plus grande
permet souvent une meilleure capture des patterns complexes, bien que
cela puisse augmenter le temps de calcul. Cette partie vise à explorer
comment la performance des modèles évolue en fonction de la quantité de
données d’entraînement disponibles. Pour ce faire, nous analysons les
performances des modèles développés dans le projet (régression linéaire,
Random Forest, Gradient Boosting, etc.) en variant progressivement la
taille des données d’entraînement (10, 50, 100, 250, …).</p>
<p>Parmi les modèles développés, Gradient Boosting a été retenu pour
cette analyse détaillée. Ce choix s’explique par ses performances
globales élevées lors des phases précédentes, ainsi que par sa
sensibilité aux variations dans les données d’entraînement.
Contrairement à des modèles comme Random Forest, qui sont moins
sensibles à la taille des données grâce à leur approche de bagging,
Gradient Boosting construit ses prédictions de manière incrémentale, ce
qui le rend particulièrement adapté pour observer l’influence des
données sur la précision des prédictions. Ainsi, cette approche nous
permettra de mieux comprendre l’effet de la quantité de données sur un
modèle puissant et flexible tout en conservant un point de comparaison
avec les autres modèles du projet.</p>
</div>
<div class="cell code" data-execution_count="30">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fonction pour évaluer les performances des modèles en fonction de la taille des données</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_models(data_train, target_train, data_test, target_test, model, sizes):</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Évalue les performances d&#39;un modèle sur des tailles croissantes de données d&#39;entraînement.</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co">        data_train (pd.DataFrame or np.ndarray): Les données d&#39;entraînement.</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co">        target_train (pd.Series or np.ndarray): Les cibles associées aux données d&#39;entraînement.</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co">        data_test (pd.DataFrame or np.ndarray): Les données de test.</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co">        target_test (pd.Series or np.ndarray): Les cibles associées aux données de test.</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co">        model: Le modèle à entraîner (doit implémenter `.fit()` et `.predict()`).</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co">        sizes (list[int]): Une liste de tailles pour limiter les données d&#39;entraînement.</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="co">        tuple: Trois listes contenant respectivement les scores MAE, RMSE et R².</span></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    mae_scores <span class="op">=</span> []</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>    rmse_scores <span class="op">=</span> []</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>    r2_scores <span class="op">=</span> []</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> size <span class="kw">in</span> sizes:</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Limitation des données d&#39;entraînement à la taille définie</span></span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>        data_subset <span class="op">=</span> data_train[:size]</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>        target_subset <span class="op">=</span> target_train[:size]</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Entraînement du modèle</span></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>        model.fit(data_subset, target_subset)</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prédiction sur les données de test</span></span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> model.predict(data_test)</span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calcul des métriques</span></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>        mae_scores.append(mean_absolute_error(target_test, predictions))</span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a>        rmse_scores.append(np.sqrt(mean_squared_error(target_test, predictions)))</span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a>        r2_scores.append(r2_score(target_test, predictions))</span>
<span id="cb50-36"><a href="#cb50-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-37"><a href="#cb50-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mae_scores, rmse_scores, r2_scores</span>
<span id="cb50-38"><a href="#cb50-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-39"><a href="#cb50-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-40"><a href="#cb50-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration des tailles des données d&#39;entraînement</span></span>
<span id="cb50-41"><a href="#cb50-41" aria-hidden="true" tabindex="-1"></a>sizes <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>, <span class="bu">len</span>(data_prix_train)]</span>
<span id="cb50-42"><a href="#cb50-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-43"><a href="#cb50-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Modèles à comparer</span></span>
<span id="cb50-44"><a href="#cb50-44" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {</span>
<span id="cb50-45"><a href="#cb50-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Régression Linéaire&quot;</span>: LinearRegression(),</span>
<span id="cb50-46"><a href="#cb50-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Random Forest&quot;</span>: RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb50-47"><a href="#cb50-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Gradient Boosting&quot;</span>: GradientBoostingRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">5</span>, learning_rate<span class="op">=</span><span class="fl">0.05</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb50-48"><a href="#cb50-48" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-49"><a href="#cb50-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-50"><a href="#cb50-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialisation des résultats</span></span>
<span id="cb50-51"><a href="#cb50-51" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb50-52"><a href="#cb50-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-53"><a href="#cb50-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Évaluation de chaque modèle</span></span>
<span id="cb50-54"><a href="#cb50-54" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> models.items():</span>
<span id="cb50-55"><a href="#cb50-55" aria-hidden="true" tabindex="-1"></a>    mae_scores, rmse_scores, r2_scores <span class="op">=</span> evaluate_models(data_prix_train, price_train, data_prix_test, price_test, model, sizes)</span>
<span id="cb50-56"><a href="#cb50-56" aria-hidden="true" tabindex="-1"></a>    results[name] <span class="op">=</span> {<span class="st">&quot;MAE&quot;</span>: mae_scores, <span class="st">&quot;RMSE&quot;</span>: rmse_scores, <span class="st">&quot;R2&quot;</span>: r2_scores}</span>
<span id="cb50-57"><a href="#cb50-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-58"><a href="#cb50-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualisation des résultats</span></span>
<span id="cb50-59"><a href="#cb50-59" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb50-60"><a href="#cb50-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-61"><a href="#cb50-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Graphique MAE</span></span>
<span id="cb50-62"><a href="#cb50-62" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb50-63"><a href="#cb50-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> results:</span>
<span id="cb50-64"><a href="#cb50-64" aria-hidden="true" tabindex="-1"></a>    plt.plot(sizes, results[name][<span class="st">&quot;MAE&quot;</span>], label<span class="op">=</span>name)</span>
<span id="cb50-65"><a href="#cb50-65" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Performance en fonction de la taille des données - MAE&quot;</span>)</span>
<span id="cb50-66"><a href="#cb50-66" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Taille des données d&#39;entraînement&quot;</span>)</span>
<span id="cb50-67"><a href="#cb50-67" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;MAE&quot;</span>)</span>
<span id="cb50-68"><a href="#cb50-68" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb50-69"><a href="#cb50-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-70"><a href="#cb50-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Graphique RMSE</span></span>
<span id="cb50-71"><a href="#cb50-71" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb50-72"><a href="#cb50-72" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> results:</span>
<span id="cb50-73"><a href="#cb50-73" aria-hidden="true" tabindex="-1"></a>    plt.plot(sizes, results[name][<span class="st">&quot;RMSE&quot;</span>], label<span class="op">=</span>name)</span>
<span id="cb50-74"><a href="#cb50-74" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Performance en fonction de la taille des données - RMSE&quot;</span>)</span>
<span id="cb50-75"><a href="#cb50-75" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Taille des données d&#39;entraînement&quot;</span>)</span>
<span id="cb50-76"><a href="#cb50-76" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;RMSE&quot;</span>)</span>
<span id="cb50-77"><a href="#cb50-77" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb50-78"><a href="#cb50-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-79"><a href="#cb50-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Graphique R²</span></span>
<span id="cb50-80"><a href="#cb50-80" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb50-81"><a href="#cb50-81" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> results:</span>
<span id="cb50-82"><a href="#cb50-82" aria-hidden="true" tabindex="-1"></a>    plt.plot(sizes, results[name][<span class="st">&quot;R2&quot;</span>], label<span class="op">=</span>name)</span>
<span id="cb50-83"><a href="#cb50-83" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Performance en fonction de la taille des données - R2&quot;</span>)</span>
<span id="cb50-84"><a href="#cb50-84" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Taille des données d&#39;entraînement&quot;</span>)</span>
<span id="cb50-85"><a href="#cb50-85" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;R2&quot;</span>)</span>
<span id="cb50-86"><a href="#cb50-86" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb50-87"><a href="#cb50-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-88"><a href="#cb50-88" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb50-89"><a href="#cb50-89" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_1d9dc9cb301e4125822738867a6edd77/737a31ae306c09c2fa50159fd18b48fdab844689.png" /></p>
</div>
</div>
<div class="cell markdown">
<p><strong>Analyse des graphiques</strong></p>
<p>L’analyse des performances en fonction de la taille des données
d’entraînement montre des tendances significatives pour les trois
modèles : régression linéaire, Random Forest, et Gradient Boosting. Pour
le MAE et le RMSE, les modèles non linéaires (Random Forest et Gradient
Boosting) surpassent systématiquement la régression linéaire,
particulièrement pour les tailles de données importantes, indiquant leur
capacité à capturer des relations complexes dans les données. Le
Gradient Boosting, en particulier, atteint les meilleures performances
pour les grands ensembles de données, avec des erreurs plus faibles (MAE
et RMSE). En revanche, la régression linéaire montre une convergence
plus lente, restant inférieure même à partir de petites tailles
d’entraînement. En termes de R², les modèles ensemblistes (Random Forest
et Gradient Boosting) montrent une amélioration rapide de la qualité
d’ajustement dès 100 échantillons, dépassant la régression linéaire, qui
reste moins performante pour expliquer la variance. Ainsi, le Gradient
Boosting se révèle être le modèle optimal, combinant une faible erreur
et une meilleure généralisation, particulièrement pertinent pour des
ensembles de données d’entraînement de grande taille.</p>
<h1 id="vii-conclusion-générale"><span
class="math inline"><em>V</em><em>I</em><em>I</em></span>. Conclusion
Générale</h1>
<h2 id="résumé-du-projet">Résumé du Projet</h2>
<p>Le projet visait à développer un modèle performant pour prédire les
prix des maisons en fonction de leurs caractéristiques, telles que la
superficie, le nombre de chambres, et d’autres commodités. La
problématique sous-jacente était de comprendre les facteurs clés
influençant le prix des maisons, tout en fournissant un modèle précis et
interprétable pour les professionnels de l’immobilier. Pour cela, nous
avons appliqué des techniques de data science en utilisant plusieurs
modèles parmi lesquels <strong>Random Forest</strong> et
<strong>Gradient Boosting</strong>, et avons optimisé leurs performances
grâce à des approches avancées comme <strong>RandomizedSearchCV</strong>
et <strong>GridSearchCV</strong>.</p>
<h2 id="analyse-des-modèles-développés">Analyse des Modèles
Développés</h2>
<p>Au cours de ce projet, plusieurs modèles, allant des modèles de base
à des algorithmes avancés, ont été testés, comparés, et optimisés pour
répondre à la problématique. Les résultats obtenus montrent que :</p>
<ol>
<li><p><strong>Modèle Basé sur les Moyennes (Baseline) :</strong> ce
modèle de référence a été construit pour évaluer les performances
minimales acceptables. Il a offert un benchmark utile mais des
performances très limitées, servant principalement à juger l’efficacité
des modèles avancés.</p></li>
<li><p><strong>Modèle de Régression linéaire :</strong> Ce modèle a
permi de poser les bases en évaluant les relations linéaires entre les
variables et le prix. Bien qu’il soit simple à interpréter, sa
performance était limitée, avec une faible capacité à capturer les
relations non linéaires complexes présentes dans les données.</p></li>
<li><p><strong>Random Forest :</strong> ce modèle ensembliste, bien
qu’efficace, a montré une grande capacité à capturer les relations
complexes grâce à son architecture basée sur des arbres de décision.
Après optimisation (max_depth = 10, n_estimators = 300), il a obtenu des
résultats solides mais légèrement surajustés sur les données
d’entraînement, indiquant une généralisation perfectible. Ses
performances étaient compétitives mais légèrement inférieures à celles
du Gradient Boosting pour les données test.</p></li>
<li><p><strong>Gradient Boosting :</strong> il s'est révélé être le
modèle le plus performant pour cette tâche, grâce à sa capacité à
généraliser sur des données non vues. Avec des hyperparamètres optimaux
tels qu’un taux d’apprentissage de <strong>0.05</strong>, une profondeur
maximale de <strong>5</strong>, et un nombre d’estimations de
<strong>200</strong>, il a offert un bon équilibre entre précision et
généralisation, tout en maîtrisant le surapprentissage. Ce modèle s’est
distingué par sa robustesse et son compromis optimal entre performance
sur les données d’entraînement et données de test.</p></li>
</ol>
<p>Enfin, l’analyse des performances en fonction de la taille des
données d’entraînement a mis en évidence l’importance cruciale d’un
grand volume de données pour améliorer la précision et la généralisation
des modèles, renforçant ainsi l’efficacité globale de la solution
proposée.</p>
<p>En conclusion, <strong>Gradient Boosting</strong> a été retenu comme
le meilleur modèle pour cette problématique de prédiction de prix.</p>
<h2 id="variables-importantes">Variables Importantes</h2>
<p>L’analyse des importances des caractéristiques a permis d’identifier
les variables ayant le plus grand impact sur la prédiction des prix des
maisons :</p>
<ul>
<li><strong>Superficie (<code>area</code>)</strong> : Variable la plus
influente, représentant environ <strong>40%</strong> de l’importance
totale. Cela confirme que la superficie est un facteur clé dans
l’évaluation des prix immobiliers.</li>
<li><strong>Nombre de salles de bain (<code>bathrooms</code>)</strong> :
Contribution significative, représentant environ <strong>27%</strong> de
l’importance.</li>
<li><strong>Parking (<code>parking</code>)</strong> : Facteur modérément
influent, avec une importance de <strong>5%</strong>.</li>
<li><strong>Nombre d’étages (<code>stories</code>)</strong> et
<strong>climatisation (<code>air_conditioning</code>)</strong> :
Variables complémentaires avec des contributions respectives de
<strong>4.5%</strong> et <strong>3.7%</strong>.</li>
</ul>
<p>D'autres variables, telles que <strong>chauffage à l’eau chaude
(<code>hotwaterheating</code>)</strong>, <strong>préférence
d’emplacement (<code>prefarea</code>)</strong>, et <strong>chambre
d’invité (<code>guestroom</code>)</strong>, ont également eu une
influence moindre mais notable.</p>
<p>En revanche, des caractéristiques comme <strong>accès à une route
principale (<code>mainroad</code>)</strong> et <strong>type
d’ameublement (<code>furnishing_status</code>)</strong> se sont avérées
négligeables dans ce contexte.</p>
<h2 id="perspectives">Perspectives</h2>
<p>Ce projet a démontré l’efficacité des modèles ensemblistes pour
résoudre des problématiques de régression complexes. Les résultats
obtenus peuvent être améliorés en :</p>
<ul>
<li>Collectant davantage de données pour renforcer la robustesse des
modèles.</li>
<li>Explorant d’autres approches, comme les réseaux neuronaux ou les
modèles basés sur des méthodes de boosting avancées comme XGBoost ou
LightGBM.</li>
<li>Intégrant des données supplémentaires sur l’environnement (écoles,
commodités, transports publics) pour capturer des facteurs externes
influençant les prix.</li>
</ul>
<p>En conclusion, le modèle Gradient Boosting optimisé avec ses
variables importantes constitue une solution fiable et précise pour
répondre à la problématique de prédiction des prix des maisons, offrant
ainsi un outil précieux pour les acteurs de l’immobilier et les
décideurs.</p>
</div>
</body>
</html>
